{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EDA_TRAIN_USING_GPU",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWW2z8WE2eMG"
      },
      "source": [
        "# ================================================================================ #\n",
        "# =========================== Goolge Colab File Upload =========================== #\n",
        "# ================================================================================ #\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import output\n",
        "# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/뉴스 토픽 분류 경진대회/open2.zip\" \"open2.zip\"\n",
        "# data.zip을 현재 디렉터리에 압축해제\n",
        "!unzip \"open2.zip\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/뉴스 토픽 분류 경진대회/ko.zip\" \"ko.zip\"\n",
        "!unzip \"ko.zip\"\n",
        "output.clear()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exV0dTQE3sAj"
      },
      "source": [
        "# import library \n",
        "import numpy as np\n",
        "from numpy.lib.function_base import _cov_dispatcher\n",
        "import scipy as sp\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 한국어 형태소 및 문장 분석 라이브러리\n",
        "\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install nltk\n",
        "!pip install konlpy\n",
        "\n",
        "'''\n",
        "!git clone https://github.com/kakao/khaiii.git \n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python\n",
        "from khaiii import KhaiiiApi\n",
        "'''\n",
        "\n",
        "from konlpy.tag import Kkma\n",
        "from pykospacing import Spacing\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "output.clear()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbb2boVuiqCh",
        "outputId": "5b79a92d-f2f0-4860-b55e-4975fdbe89f3"
      },
      "source": [
        "# text data & label data load\n",
        "\n",
        "PATH = \"./\"\n",
        "df_train = pd.read_csv(PATH + \"train_data.csv\")\n",
        "df_test = pd.read_csv(PATH + \"test_data.csv\")\n",
        "topic_dict = pd.read_csv(PATH + \"topic_dict.csv\")\n",
        "kr_stopwords_list = pd.read_csv(PATH + \"korean_stopwords.csv\", header = None, names = ['word'])[\"word\"].tolist()\n",
        "\n",
        "print(\"훈련 데이터 크기: \", df_train.shape)\n",
        "print(\"예측 데이터 크기: \", df_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터 크기:  (45654, 3)\n",
            "예측 데이터 크기:  (9131, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "nyniI-s7ivcX",
        "outputId": "58ea49b3-3650-4e76-bdc2-eb8729fabdae"
      },
      "source": [
        "print(\"#훈련 데이터\")\n",
        "display(df_train.head())\n",
        "print(\"\\n#예측 데이터\")\n",
        "display(df_test.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#훈련 데이터\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                             title  topic_idx\n",
              "0      0          인천→핀란드 항공기 결항…휴가철 여행객 분통          4\n",
              "1      1    실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4\n",
              "2      2    이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4\n",
              "3      3  NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4\n",
              "4      4         시진핑 트럼프에 중미 무역협상 조속 타결 희망          4"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#예측 데이터\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45654</td>\n",
              "      <td>유튜브 내달 2일까지 크리에이터 지원 공간 운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45655</td>\n",
              "      <td>어버이날 맑다가 흐려져…남부지방 옅은 황사</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45656</td>\n",
              "      <td>내년부터 국가RD 평가 때 논문건수는 반영 않는다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45657</td>\n",
              "      <td>김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45658</td>\n",
              "      <td>회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                            title\n",
              "0  45654       유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
              "1  45655          어버이날 맑다가 흐려져…남부지방 옅은 황사\n",
              "2  45656      내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
              "3  45657  김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
              "4  45658   회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThzFj6fTkwE7",
        "outputId": "3cd85b6d-3d48-4f35-9196-8ae68fc850cd"
      },
      "source": [
        "# 뉴스 토픽 주제 분류\n",
        "print(topic_dict[\"topic\"].values)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['IT과학' '경제' '사회' '생활문화' '세계' '스포츠' '정치']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "TjERLIdjiyqx",
        "outputId": "c257e95a-093a-42ea-e7eb-d835a8d15869"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "topic_dictionary = topic_dict.to_dict\n",
        "\n",
        "def idx_to_topic(idx):\n",
        "    if idx <= len(topic_dict[\"topic\"]):\n",
        "        return topic_dict[\"topic\"][idx]\n",
        "    else:\n",
        "        ValueError(\"enter the index below the length of topic_idx\")\n",
        "\n",
        "datasets_eda = df_train.copy()\n",
        "datasets_eda[\"topic\"] = datasets_eda.loc[:, \"topic_idx\"].apply(idx_to_topic).values.reshape(-1,1)\n",
        "\n",
        "#sns.countplot( x = \"topic\", data = datasets_eda) # 한글은 출력 안됨....\n",
        "sns.countplot(df_train[\"topic_idx\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd0974088d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "txSUg8xQosgL",
        "outputId": "5e6523a9-e5d3-45a7-f7f6-1d891d4758ff"
      },
      "source": [
        "# 문장별 구성 단어 수 vs 텍스트 문서의 수\n",
        "datasets_eda[\"doc_len\"] = datasets_eda.title.apply(lambda words : len(words.split()))\n",
        "sns.countplot(x = \"doc_len\", data = datasets_eda)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd0bc2fc6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLvxVHIW3c1n",
        "outputId": "b0596c12-4f2e-4387-83b6-0d9382545e67"
      },
      "source": [
        "datasets_eda[datasets_eda[\"doc_len\"] == 2][\"title\"]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1101             건배하는 김정은시진핑\n",
              "1220                C페스티벌 개막\n",
              "1485                 신간 지옥사원\n",
              "1750                 신간 틈새경제\n",
              "2061               인사말하는 진선미\n",
              "                ...         \n",
              "44040             미디어교육원 개관식\n",
              "44776       한국소설문학상에 정수남·박영래\n",
              "44796               융합교육의 현장\n",
              "44912    기자회견하는 인천국제공항보안검색노조\n",
              "45592                  신간 참선\n",
              "Name: title, Length: 185, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWW_zJaa3orm",
        "outputId": "28ffa1ab-a6db-4d51-b240-3f506d5a6bf2"
      },
      "source": [
        "datasets_eda[datasets_eda[\"doc_len\"] == 1][\"title\"]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20911           함께아리랑\n",
              "27489      WatchPlay란\n",
              "43922            국무회의\n",
              "45153    노사관계발전자문위원회의\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lSder_vm1yAg",
        "outputId": "bd9e9cfc-3939-4474-f397-24f08ee69491"
      },
      "source": [
        "obs_len = 5\n",
        "\n",
        "print(\"# topic : IT과학 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 0][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 경제 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 1][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 사회 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 2][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 생활문화 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 3][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 세계 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 4][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 스포츠 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 5][0:obs_len])\n",
        "\n",
        "print(\"\\n# topic : 정치 #\")\n",
        "display(datasets_eda[datasets_eda[\"topic_idx\"] == 6][0:obs_len])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# topic : IT과학 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>617</td>\n",
              "      <td>지카바이러스도 규명한 초저온전자현미경…신약연구에 유용</td>\n",
              "      <td>0</td>\n",
              "      <td>IT과학</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>622</td>\n",
              "      <td>증강현실 ① 알파고 이어 포켓몬 고…거센 IT 광풍</td>\n",
              "      <td>0</td>\n",
              "      <td>IT과학</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>643</td>\n",
              "      <td>AI 월드컵 생생한 현장 중계도</td>\n",
              "      <td>0</td>\n",
              "      <td>IT과학</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>654</td>\n",
              "      <td>이세돌 알파고 집중력 사람이 이기긴 어렵다 일문일답종합2보</td>\n",
              "      <td>0</td>\n",
              "      <td>IT과학</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>660</td>\n",
              "      <td>올해 휴대폰 국내 생산량 2천500만대…10년전의 18.4%</td>\n",
              "      <td>0</td>\n",
              "      <td>IT과학</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                              title  topic_idx topic  doc_len\n",
              "617    617      지카바이러스도 규명한 초저온전자현미경…신약연구에 유용          0  IT과학        4\n",
              "622    622       증강현실 ① 알파고 이어 포켓몬 고…거센 IT 광풍          0  IT과학        8\n",
              "643    643                  AI 월드컵 생생한 현장 중계도          0  IT과학        5\n",
              "654    654   이세돌 알파고 집중력 사람이 이기긴 어렵다 일문일답종합2보          0  IT과학        7\n",
              "660    660  올해 휴대폰 국내 생산량 2천500만대…10년전의 18.4%          0  IT과학        6"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 경제 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>761</td>\n",
              "      <td>못믿을 아파트 관리비…경기 556곳서 150억 비리 적발종합</td>\n",
              "      <td>1</td>\n",
              "      <td>경제</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>765</td>\n",
              "      <td>특징주 관리종목 해제 대우조선해양 강세</td>\n",
              "      <td>1</td>\n",
              "      <td>경제</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>767</td>\n",
              "      <td>특징주 강원랜드 실적 부진에 급락종합</td>\n",
              "      <td>1</td>\n",
              "      <td>경제</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>769</td>\n",
              "      <td>라면 수출 질주…올해 4억달러 첫 돌파 확실시</td>\n",
              "      <td>1</td>\n",
              "      <td>경제</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>774</td>\n",
              "      <td>경기지표 부진 골드만삭스 한은 금리인상 예상시기 7→10월로종합</td>\n",
              "      <td>1</td>\n",
              "      <td>경제</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                title  topic_idx topic  doc_len\n",
              "761    761    못믿을 아파트 관리비…경기 556곳서 150억 비리 적발종합          1    경제        7\n",
              "765    765                특징주 관리종목 해제 대우조선해양 강세          1    경제        5\n",
              "767    767                 특징주 강원랜드 실적 부진에 급락종합          1    경제        5\n",
              "769    769            라면 수출 질주…올해 4억달러 첫 돌파 확실시          1    경제        7\n",
              "774    774  경기지표 부진 골드만삭스 한은 금리인상 예상시기 7→10월로종합          1    경제        7"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 사회 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2458</th>\n",
              "      <td>2458</td>\n",
              "      <td>드라마 제작환경 개선 촉구</td>\n",
              "      <td>2</td>\n",
              "      <td>사회</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2460</th>\n",
              "      <td>2460</td>\n",
              "      <td>창원세계사격대회장서 경남 시·군 관광 세계에 알린다종합</td>\n",
              "      <td>2</td>\n",
              "      <td>사회</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>2465</td>\n",
              "      <td>조배숙 중앙위 정례회의 주재</td>\n",
              "      <td>2</td>\n",
              "      <td>사회</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2474</td>\n",
              "      <td>인천공항→송도 택시요금 12만원…바가지 택시·콜밴</td>\n",
              "      <td>2</td>\n",
              "      <td>사회</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2478</th>\n",
              "      <td>2478</td>\n",
              "      <td>조용중 전 연합뉴스 사장 별세</td>\n",
              "      <td>2</td>\n",
              "      <td>사회</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      index                           title  topic_idx topic  doc_len\n",
              "2458   2458                  드라마 제작환경 개선 촉구          2    사회        4\n",
              "2460   2460  창원세계사격대회장서 경남 시·군 관광 세계에 알린다종합          2    사회        6\n",
              "2465   2465                 조배숙 중앙위 정례회의 주재          2    사회        4\n",
              "2474   2474     인천공항→송도 택시요금 12만원…바가지 택시·콜밴          2    사회        4\n",
              "2478   2478                조용중 전 연합뉴스 사장 별세          2    사회        5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 생활문화 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>953</td>\n",
              "      <td>황석영 작가 미국 문학축제서 한국문학 알린다</td>\n",
              "      <td>3</td>\n",
              "      <td>생활문화</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>960</td>\n",
              "      <td>휴일 불청객 울산 미세먼지 주의보 발령</td>\n",
              "      <td>3</td>\n",
              "      <td>생활문화</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>963</td>\n",
              "      <td>김수영 신임 한국출판문화산업진흥원장</td>\n",
              "      <td>3</td>\n",
              "      <td>생활문화</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>965</th>\n",
              "      <td>965</td>\n",
              "      <td>신간 한반도평화 오디세이</td>\n",
              "      <td>3</td>\n",
              "      <td>생활문화</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>968</td>\n",
              "      <td>2019 가극 금강 낭독공연 간담회</td>\n",
              "      <td>3</td>\n",
              "      <td>생활문화</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                     title  topic_idx topic  doc_len\n",
              "953    953  황석영 작가 미국 문학축제서 한국문학 알린다          3  생활문화        6\n",
              "960    960     휴일 불청객 울산 미세먼지 주의보 발령          3  생활문화        6\n",
              "963    963       김수영 신임 한국출판문화산업진흥원장          3  생활문화        3\n",
              "965    965             신간 한반도평화 오디세이          3  생활문화        3\n",
              "968    968       2019 가극 금강 낭독공연 간담회          3  생활문화        5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 세계 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n",
              "      <td>4</td>\n",
              "      <td>세계</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n",
              "      <td>4</td>\n",
              "      <td>세계</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n",
              "      <td>4</td>\n",
              "      <td>세계</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n",
              "      <td>4</td>\n",
              "      <td>세계</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n",
              "      <td>4</td>\n",
              "      <td>세계</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                             title  topic_idx topic  doc_len\n",
              "0      0          인천→핀란드 항공기 결항…휴가철 여행객 분통          4    세계        5\n",
              "1      1    실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4    세계        6\n",
              "2      2    이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4    세계        8\n",
              "3      3  NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4    세계        7\n",
              "4      4         시진핑 트럼프에 중미 무역협상 조속 타결 희망          4    세계        7"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 스포츠 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>박찬호 현진이 10승 하니깐 생각이 나는데…</td>\n",
              "      <td>5</td>\n",
              "      <td>스포츠</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>고군분투 시즌 서재덕 MVP 덕큐리로 활짝 웃다종합</td>\n",
              "      <td>5</td>\n",
              "      <td>스포츠</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>임도헌 감독 신영석 중심으로 똘똘 뭉쳐 한일전 승리 따냈다</td>\n",
              "      <td>5</td>\n",
              "      <td>스포츠</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>데얀·김치우 OUT 조영욱 IN…서울 과감한 재건 성과...</td>\n",
              "      <td>5</td>\n",
              "      <td>스포츠</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>호날두 노쇼 유벤투스 무책임·거만 비판 수용 어려워</td>\n",
              "      <td>5</td>\n",
              "      <td>스포츠</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                              title  topic_idx topic  doc_len\n",
              "52     52           박찬호 현진이 10승 하니깐 생각이 나는데…          5   스포츠        6\n",
              "54     54       고군분투 시즌 서재덕 MVP 덕큐리로 활짝 웃다종합          5   스포츠        7\n",
              "58     58   임도헌 감독 신영석 중심으로 똘똘 뭉쳐 한일전 승리 따냈다          5   스포츠        9\n",
              "63     63  데얀·김치우 OUT 조영욱 IN…서울 과감한 재건 성과...          5   스포츠        7\n",
              "66     66       호날두 노쇼 유벤투스 무책임·거만 비판 수용 어려워          5   스포츠        7"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# topic : 정치 #\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "      <th>topic</th>\n",
              "      <th>doc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>김영남 우리 민족 위상 과시…뜨거운 분위기 이어가길</td>\n",
              "      <td>6</td>\n",
              "      <td>정치</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>적극행정 추진전략 및 성과공유대회 참석한 이낙연 총리</td>\n",
              "      <td>6</td>\n",
              "      <td>정치</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>朴대통령 한일 합의에 소녀상 언급없어…선동하면 안돼</td>\n",
              "      <td>6</td>\n",
              "      <td>정치</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>민주 국회의원 재보선 4곳 후보 공모에 7명 신청</td>\n",
              "      <td>6</td>\n",
              "      <td>정치</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>현행 헌법과 다른 점은 ②지방자치·경제민주화 개념 강화</td>\n",
              "      <td>6</td>\n",
              "      <td>정치</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                           title  topic_idx topic  doc_len\n",
              "43     43    김영남 우리 민족 위상 과시…뜨거운 분위기 이어가길          6    정치        7\n",
              "48     48   적극행정 추진전략 및 성과공유대회 참석한 이낙연 총리          6    정치        7\n",
              "49     49    朴대통령 한일 합의에 소녀상 언급없어…선동하면 안돼          6    정치        6\n",
              "50     50     민주 국회의원 재보선 4곳 후보 공모에 7명 신청          6    정치        8\n",
              "53     53  현행 헌법과 다른 점은 ②지방자치·경제민주화 개념 강화          6    정치        7"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRLTeq5q4zRb"
      },
      "source": [
        "# preprocessing\n",
        "# 한국어 불용어 처리\n",
        "# re를 통한 정규화\n",
        "# spacing 혹은 pos taging을 통해 명사만을 추출한다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFkFVrt243ot"
      },
      "source": [
        "# 전처리 진행\n",
        "- 불용어 처리\n",
        "- pos taging을 이용한 명사 추출(접두사, 어미 제거)\n",
        "- re 라이브러리를 이용한 정규화(html 태그 및 각종 수식 문구 제거)\n",
        "- stemming / lemmatization : 어간 추출 및 표제어 추출\n",
        "- 논의사항:\n",
        "    1) 외래어, 영문자는 제거해야 하는가?\n",
        "    2) 한문(미, 중, 러) 표기는 무시해야 하는가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XsoUuImc5wyA",
        "outputId": "0f3b571e-7cc6-4dc5-ce28-3b5472fedb2e"
      },
      "source": [
        "# 형태소 분석(konlpy의 Kkma 이용)\n",
        "# 관련 알고리즘 : \n",
        "# 1번 자료: http://kkma.snu.ac.kr/documents/\n",
        "# 2번 자료: https://konlpy-ko.readthedocs.io/ko/v0.4.3/\n",
        "\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "kkma = Kkma()\n",
        "\n",
        "idx_random = np.random.randint(0,len(df_train), size = 100, dtype = int)\n",
        "samples = df_train.iloc[idx_random]\n",
        "\n",
        "display(samples)\n",
        "\n",
        "samples_pos_tag = [kkma.pos(text) for text in samples[\"title\"].values]\n",
        "\n",
        "for i in range(len(idx_random)):\n",
        "    print(samples_pos_tag[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39723</th>\n",
              "      <td>39723</td>\n",
              "      <td>사랑이 넘치면서 부재하는 시대에 찾아온 사랑잡가</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>805</td>\n",
              "      <td>도쿄 국기관 방문한 트럼프와 아베</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8070</th>\n",
              "      <td>8070</td>\n",
              "      <td>밸런타인데이에 만나는 예술의전당 11시 콘서트</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43130</th>\n",
              "      <td>43130</td>\n",
              "      <td>이재영 여자 정지석 지석 오빠 진짜 잘하시던데요</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45465</th>\n",
              "      <td>45465</td>\n",
              "      <td>1보 코스피 또 3%대 폭락해 1780선 붕괴 마감</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40189</th>\n",
              "      <td>40189</td>\n",
              "      <td>산재 처벌 대상 사업주로 명시해야…기업엔 매출 따라 벌금</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15147</th>\n",
              "      <td>15147</td>\n",
              "      <td>프로농구 챔피언 1차전 부진 SK 메이스 동료 선수들에 사과</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31750</th>\n",
              "      <td>31750</td>\n",
              "      <td>여자배구 GS칼텍스 알리 부상 딛고 IBK기업은행에 3...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33989</th>\n",
              "      <td>33989</td>\n",
              "      <td>NH농협 코스피200지수 연동예금 출시…최고 연 4.15% 수익</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16920</th>\n",
              "      <td>16920</td>\n",
              "      <td>권창훈 프랑스 디종 이적 확정…유럽진출 꿈 이뤘다</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                title  topic_idx\n",
              "39723  39723           사랑이 넘치면서 부재하는 시대에 찾아온 사랑잡가          3\n",
              "805      805                   도쿄 국기관 방문한 트럼프와 아베          4\n",
              "8070    8070            밸런타인데이에 만나는 예술의전당 11시 콘서트          3\n",
              "43130  43130           이재영 여자 정지석 지석 오빠 진짜 잘하시던데요          5\n",
              "45465  45465         1보 코스피 또 3%대 폭락해 1780선 붕괴 마감          1\n",
              "...      ...                                  ...        ...\n",
              "40189  40189      산재 처벌 대상 사업주로 명시해야…기업엔 매출 따라 벌금          2\n",
              "15147  15147    프로농구 챔피언 1차전 부진 SK 메이스 동료 선수들에 사과          5\n",
              "31750  31750    여자배구 GS칼텍스 알리 부상 딛고 IBK기업은행에 3...          5\n",
              "33989  33989  NH농협 코스피200지수 연동예금 출시…최고 연 4.15% 수익          1\n",
              "16920  16920          권창훈 프랑스 디종 이적 확정…유럽진출 꿈 이뤘다          5\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[('사랑', 'NNG'), ('이', 'JKS'), ('넘치', 'VV'), ('면서', 'ECE'), ('부재', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('시대', 'NNG'), ('에', 'JKM'), ('찾아오', 'VV'), ('ㄴ', 'ETD'), ('사랑', 'NNG'), ('잡가', 'NNG')]\n",
            "[('도쿄', 'NNP'), ('국', 'NNG'), ('기관', 'NNG'), ('방문', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('트럼프', 'NNG'), ('와', 'JC'), ('아베', 'NNP')]\n",
            "[('배', 'VV'), ('ㄹ', 'ETD'), ('런', 'NNG'), ('타인', 'NNG'), ('데이', 'NNG'), ('에', 'JKM'), ('만나', 'VV'), ('는', 'ETD'), ('예술', 'NNG'), ('의', 'JKG'), ('전당', 'NNG'), ('11', 'NR'), ('시', 'NNG'), ('콘서트', 'NNG')]\n",
            "[('이재', 'NNG'), ('영', 'NNG'), ('여자', 'NNG'), ('정지', 'NNG'), ('석', 'MDN'), ('지석', 'NNG'), ('오빠', 'NNG'), ('진짜', 'MAG'), ('잘하', 'VV'), ('시', 'EPH'), ('던데요', 'ECD')]\n",
            "[('1', 'NR'), ('보', 'NNM'), ('코스', 'NNG'), ('피', 'NNG'), ('또', 'MAG'), ('3', 'NR'), ('%', 'SW'), ('대', 'NNG'), ('폭락', 'NNG'), ('하', 'XSV'), ('어', 'ECS'), ('1780', 'NR'), ('선', 'NNG'), ('붕괴', 'NNG'), ('마감', 'NNG')]\n",
            "[('인권위', 'NNG'), ('스포츠', 'NNG'), ('인권', 'NNG'), ('현장', 'NNG'), ('조사', 'NNG'), ('…', 'SE'), ('학교', 'NNG'), ('운동부', 'NNG'), ('훈련', 'NNG'), ('실태', 'NNG'), ('등', 'NNB'), ('점검', 'NNG')]\n",
            "[('국제', 'NNG'), ('사회', 'NNG'), ('北', 'OH'), ('인권', 'NNG'), ('문제', 'NNG'), ('대응', 'NNG'), ('잰걸음', 'NNG'), ('…', 'SE'), ('국내외', 'NNG'), ('서', 'JKM'), ('잇닿', 'VV'), ('ㄴ', 'ETD'), ('행사', 'NNG')]\n",
            "[('남북', 'NNG'), ('미일', 'NNG'), ('중', 'NNB'), ('정상급', 'NNG'), ('평', 'NNG'), ('창', 'NNG'), ('리셉션', 'NNG'), ('참석', 'NNG'), ('…', 'SE'), ('펜스', 'NNG'), ('·', 'SP'), ('김', 'NNG'), ('영남', 'NNG'), ('악수', 'NNG'), ('없', 'VA'), ('었', 'EPT'), ('다', 'EFN')]\n",
            "[('표류', 'NNG'), ('북한', 'NNG'), ('주민', 'NNG'), ('구조', 'NNG'), ('선장', 'NNG'), ('팬티', 'NNG'), ('만', 'JX'), ('입', 'NNG'), ('은', 'JX'), ('채', 'MAG'), ('손', 'NNG'), ('흔들', 'VV'), ('어', 'ECD')]\n",
            "[('박', 'NNG'), ('병', 'NNG'), ('호', 'NNG'), ('결승', 'NNG'), ('밀어내', 'VV'), ('기', 'ETN'), ('볼넷', 'NNG'), ('…', 'SE'), ('넥센', 'NNP'), ('SK', 'OL'), ('3', 'NR'), ('연', 'NNG'), ('전', 'NNG'), ('위', 'NNG'), ('닝', 'UN'), ('시리즈', 'NNG')]\n",
            "[('키', 'NNG'), ('움', 'NNG'), ('증권', 'NNG'), ('올해', 'NNG'), ('면세점', 'NNG'), ('시장', 'NNG'), ('20', 'NR'), ('%', 'SW'), ('이상', 'NNG'), ('성장', 'NNG'), ('가능성', 'NNG')]\n",
            "[('입추', 'NNG'), ('에', 'JKM'), ('도', 'JX'), ('전국', 'NNG'), ('폭염', 'NNG'), ('…', 'SE'), ('중부', 'NNG'), ('아침', 'NNG'), ('비', 'NNG'), ('·', 'SP'), ('경남', 'NNP'), ('내륙', 'NNG'), ('오후', 'NNG'), ('소나기', 'NNG')]\n",
            "[('제주', 'NNG'), ('고사리', 'NNG'), ('맛', 'NNG'), ('도', 'JX'), ('영양', 'NNG'), ('도', 'JX'), ('만점', 'NNG'), ('에', 'JKM'), ('꺾', 'VV'), ('는', 'ETD'), ('재미', 'NNG'), ('까지', 'JX')]\n",
            "[('美', 'OH'), ('국무부', 'NNG'), ('일각', 'NNG'), ('시리아', 'NNG'), ('에', 'JKM'), ('제한', 'NNG'), ('적', 'XSN'), ('군사력', 'NNG'), ('사용', 'NNG'), ('주장', 'NNG')]\n",
            "[('중국', 'NNG'), ('핵', 'NNG'), ('무기', 'NNG'), ('는', 'JX'), ('위협', 'NNG'), ('안', 'MAG'), ('되', 'VV'), ('어', 'ECS'), ('…', 'SE'), ('中', 'OH'), ('INF', 'OL'), ('참여', 'NNG'), ('요구', 'NNG'), ('거부', 'NNG')]\n",
            "[('8', 'NR'), ('월', 'NNM'), ('하순', 'NNG'), ('이', 'VCP'), ('ㄴ데', 'ECE'), ('열대야', 'NNG'), ('가', 'JKS'), ('…', 'SE'), ('제주', 'NNG'), ('열대야', 'NNG'), ('44', 'NR'), ('일', 'NNM'), ('로', 'JKM'), ('역대', 'NNG'), ('3', 'NR'), ('번째', 'NNB')]\n",
            "[('베트남전', 'NNG'), ('찾', 'VV'), ('은', 'ETD'), ('박', 'NNG'), ('항서', 'NNG'), ('감독', 'NNG'), ('베트남', 'NNG'), ('강하', 'VV'), ('ㅂ니다', 'EFN')]\n",
            "[('지난해', 'NNG'), ('미국', 'NNP'), ('·', 'SP'), ('유럽', 'NNG'), ('여행', 'NNG'), ('에', 'JKM'), ('쓰', 'VV'), ('ㄴ', 'ETD'), ('돈', 'NNG'), ('줄', 'VV'), ('고', 'ECE'), ('일본', 'NNG'), ('·', 'SP'), ('동남아', 'NNG'), ('는', 'JX'), ('늘', 'VV'), ('었', 'EPT'), ('다', 'EFN')]\n",
            "[('中', 'OH'), ('사', 'VV'), ('아', 'ECS'), ('드', 'XPN'), ('보복', 'NNG'), ('6', 'NR'), ('개월', 'NNM'), ('방한', 'NNG'), ('동남아', 'NNG'), ('관광객', 'NNG'), ('도', 'JX'), ('줄', 'VV'), ('었', 'EPT'), ('다', 'ECS'), ('…', 'SE'), ('1.5', 'NR'), ('%', 'SW'), ('감소', 'NNG')]\n",
            "[('홍', 'NNG'), ('콩', 'NNG'), ('서', 'JKM'), ('美', 'OH'), ('홍', 'NNG'), ('콩', 'NNG'), ('인권', 'NNG'), ('법안', 'NNG'), ('통과', 'NNG'), ('촉구', 'NNG'), ('대규모', 'NNG'), ('집회', 'NNG')]\n",
            "[('문', 'NNG'), ('대통령', 'NNG'), ('아이스하키', 'NNG'), ('팀', 'NNG'), ('에게', 'JKM'), ('엄', 'VA'), ('지', 'ECD'), ('척', 'NNB')]\n",
            "[('3', 'NR'), ('점', 'NNM'), ('포', 'NNG'), ('24', 'NR'), ('개', 'NNM'), ('NBA', 'OL'), ('보스턴', 'NNG'), ('밀워키', 'NNG'), ('에', 'JKM'), ('시즌', 'NNG'), ('첫', 'MDT'), ('패배', 'NNG'), ('안기', 'VV'), ('어', 'ECS')]\n",
            "[('다음', 'NNG'), ('PC', 'OL'), ('메일', 'NNG'), ('쓰', 'VV'), ('면서', 'ECE'), ('카', 'VV'), ('아', 'ECS'), ('톡', 'MAG'), ('이모', 'NNG'), ('티', 'NNG'), ('콘', 'NNG'), ('사용', 'NNG')]\n",
            "[('저', 'NP'), ('의', 'JKG'), ('10', 'NR'), ('회', 'NNM'), ('방송', 'NNG'), ('통신', 'NNG'), ('이용자', 'NNG'), ('주간', 'NNG'), ('기념식', 'NNG')]\n",
            "[('당대', 'NNG'), ('최고', 'NNG'), ('포수', 'NNG'), ('양', 'NNG'), ('의지', 'NNG'), ('125', 'NR'), ('억', 'NR'), ('원', 'NNM'), ('에', 'JKM'), ('NC', 'OL'), ('행', 'NNG')]\n",
            "[('신간', 'NNG'), ('어둠', 'NNG'), ('을', 'JKO'), ('먹', 'VV'), ('는', 'ETD'), ('사람', 'NNG'), ('들', 'XSN'), ('·', 'SP'), ('거의', 'MAG'), ('완벽', 'NNG'), ('에', 'JKM'), ('가깝', 'VA'), ('ㄴ', 'ETD'), ('사람', 'NNG'), ('들', 'XSN')]\n",
            "[('전국구', 'NNG'), ('스타', 'NNG'), ('류', 'NNG'), ('현진', 'NNP'), ('22', 'NR'), ('서', 'NNG'), ('교체', 'NNG'), ('…', 'SE'), ('7', 'NR'), ('이닝', 'NNG'), ('8', 'NR'), ('타', 'VV'), ('ㄹ', 'ETD'), ('삼진', 'NNG'), ('2', 'NR'), ('실점', 'NNG'), ('...', 'SE')]\n",
            "[('실종자', 'NNG'), ('수색', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('소방', 'NNG'), ('구조대', 'NNG')]\n",
            "[('STC', 'OL'), ('이란', 'JX'), ('에', 'JC'), ('600', 'NR'), ('억', 'NR'), ('원', 'NNM'), ('대', 'NNG'), ('플랜트', 'NNG'), ('기자재', 'NNG'), ('공급', 'NNG'), ('계약', 'NNG'), ('체결', 'NNG')]\n",
            "[('4', 'NR'), ('인치', 'NNM'), ('미만', 'NNG'), ('스마트', 'NNP'), ('폰', 'NNG'), ('사라지', 'VV'), ('ㄴ다', 'ECS'), ('…', 'SE'), ('5.5', 'NR'), ('인치', 'NNG'), ('가', 'JKS'), ('대세', 'NNG')]\n",
            "[('몰래', 'MAG'), ('의자', 'NNG'), ('뒤', 'NNG'), ('로', 'JKM'), ('빼', 'VV'), ('동료', 'UN'), ('엉덩방아', 'NNG'), ('찧', 'VV'), ('게', 'ECD'), ('한', 'MDN'), ('60', 'NR'), ('대', 'NNM'), ('벌금형', 'NNG')]\n",
            "[('배구', 'NNG'), ('협회', 'NNG'), ('최초', 'NNG'), ('로', 'JKM'), ('남녀', 'NNG'), ('국가', 'NNG'), ('대표', 'NNG'), ('전임', 'NNG'), ('감독', 'NNG'), ('제', 'XSN'), ('시행', 'NNG')]\n",
            "[('美', 'OH'), ('아이오', 'NNG'), ('와', 'JKM'), ('경선', 'NNG'), ('개표', 'NNG'), ('초반', 'NNG'), ('힐', 'NNG'), ('러', 'NNP'), ('리', 'NNG'), ('크루즈', 'NNG'), ('1', 'NR'), ('위', 'NNM')]\n",
            "[('원주', 'NNG'), ('서', 'JKM'), ('중학생', 'NNG'), ('2', 'NR'), ('명', 'NNM'), ('코로나', 'NNG'), ('19', 'NR'), ('추가', 'NNG'), ('확', 'MAG'), ('진', 'NNG'), ('…', 'SE'), ('태권', 'NNG'), ('도', 'JX'), ('장서', 'NNG'), ('감염', 'NNG')]\n",
            "[('與', 'OH'), ('몽니', 'NNG'), ('·', 'SP'), ('꼼수', 'NNG'), ('…', 'SE'), ('두렵', 'VV'), ('면', 'ECE'), ('선거제', 'NNG'), ('패스트', 'NNG'), ('트랙', 'NNG'), ('동참', 'NNG'), ('한국', 'NNG'), ('당', 'XSN'), ('압박', 'NNG')]\n",
            "[('보수', 'NNG'), ('표방', 'NNG'), ('단체', 'NNG'), ('DMZ', 'OL'), ('다큐', 'NNP'), ('상업', 'NNG'), ('광고', 'NNG'), ('사용', 'NNG'), ('JTBC', 'OL'), ('검찰', 'NNG'), ('고발', 'NNG')]\n",
            "[('경매', 'NNG'), ('가', 'JKS'), ('2030', 'NR'), ('억', 'NR'), ('추정', 'NNG'), ('되', 'XSV'), ('는', 'ETD'), ('이중섭', 'NNG'), ('소', 'NNG')]\n",
            "[('충주', 'NNP'), ('호암', 'NNG'), ('택지', 'NNG'), ('지구', 'NNG'), ('서', 'JKM'), ('4', 'NR'), ('개', 'NNM'), ('아파트', 'NNG'), ('이달', 'NNG'), ('말', 'VV'), ('ㄹ', 'ETD'), ('동시', 'NNG'), ('분양', 'NNG')]\n",
            "[('스티브', 'UN'), ('바라', 'NNG'), ('캇', 'UN'), ('서울', 'NNG'), ('남자', 'NNG'), ('평양', 'NNP'), ('여자', 'NNG'), ('교향곡', 'NNG'), ('버전', 'NNG'), ('선보이', 'VV'), ('어', 'ECS')]\n",
            "[('독일', 'NNG'), ('강제', 'NNG'), ('매춘', 'NNG'), ('종사자', 'NNG'), ('성', 'NNG'), ('매수', 'NNG'), ('때', 'VV'), ('ㄴ', 'ETD'), ('징역형', 'NNG'), ('입법', 'NNG'), ('검토', 'NNG')]\n",
            "[('글로벌', 'NNG'), ('외환', 'NNG'), ('시장', 'NNG'), ('서', 'JKM'), ('한국', 'NNG'), ('비중', 'NNG'), ('0.7', 'NR'), ('%', 'SW'), ('…', 'SE'), ('52', 'NR'), ('개국', 'NNM'), ('중', 'NNB'), ('14', 'NR'), ('위', 'NNM'), ('→', 'SW'), ('15', 'NR'), ('위', 'NNG')]\n",
            "[('두', 'MDN'), ('번째', 'NNB'), ('아트', 'NNG'), ('아시아', 'NNG'), ('개막', 'NNG'), ('…', 'SE'), ('공모전', 'NNG'), ('첫', 'MDT'), ('수상', 'NNG'), ('젊', 'VA'), ('은', 'ETD'), ('작가', 'NNG'), ('들', 'XSN'), ('주목', 'NNG')]\n",
            "[('흑', 'NNG'), ('하', 'XSV'), ('어', 'ECS'), ('케르치', 'NNG'), ('해협', 'NNG'), ('서', 'JKM'), ('탱크', 'NNG'), ('선', 'NNG'), ('2', 'NR'), ('척', 'NNM'), ('에', 'JKM'), ('화재', 'NNG'), ('…', 'SE'), ('최', 'NNP'), ('소', 'NNG'), ('10', 'NR'), ('명', 'NNM'), ('사망', 'NNG')]\n",
            "[('유조선', 'NNG'), ('피격', 'NNG'), ('에', 'JKM'), ('美', 'OH'), ('드', 'XPN'), ('론', 'NNG'), ('격추', 'NNG'), ('…', 'SE'), ('끓어오르', 'VV'), ('는', 'ETD'), ('호', 'NNG'), ('르', 'NNG'), ('무', 'NNG'), ('즈', 'UN'), ('해협', 'NNG')]\n",
            "[('재', 'XPN'), ('건축', 'NNG'), ('안전', 'NNG'), ('진단', 'NNG'), ('강화', 'NNG'), ('여파', 'NNG'), ('에', 'JKM'), ('건설', 'NNG'), ('체감', 'NNG'), ('경기', 'NNG'), ('악화', 'NNG')]\n",
            "[('내일', 'NNG'), ('꽃샘', 'NNG'), ('추위', 'NNG'), ('절정', 'NNG'), ('…', 'SE'), ('다음', 'NNG'), ('주', 'NNG'), ('부터', 'JX'), ('완연', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETD'), ('봄', 'NNG')]\n",
            "[('위', 'NNG'), ('크', 'VA'), ('ㄹ', 'ETD'), ('리', 'NNB'), ('스마트', 'NNP'), ('여름철', 'NNG'), ('짜증', 'NNG'), ('나', 'VV'), ('게', 'ECD'), ('하', 'VV'), ('는', 'ETD'), ('땀', 'NNG'), ('…', 'SE'), ('그', 'MDT'), ('속', 'NNG'), ('에', 'JKM'), ('건강', 'NNG'), ('정보', 'NNG'), ('있', 'VXV'), ('다', 'EFN')]\n",
            "[('북한', 'NNG'), ('낮', 'NNG'), ('12', 'NR'), ('시', 'NNM'), ('30', 'NR'), ('분', 'NNM'), ('특별', 'NNG'), ('중대', 'NNG'), ('보도', 'NNG'), ('예고', 'NNG'), ('…', 'SE'), ('핵실험', 'NNG'), ('발표', 'NNG'), ('하', 'XSV'), ('ㄹ', 'ETD'), ('듯', 'NNB'), ('종합', 'NNG')]\n",
            "[('관광', 'NNG'), ('공사', 'NNG'), ('지정', 'NNG'), ('굿', 'NNG'), ('스테이', 'NNG'), ('숙박', 'NNG'), ('업소', 'NNG'), ('가', 'JKS'), ('성', 'NNG'), ('매매', 'NNG'), ('장소', 'NNG'), ('제공', 'NNG')]\n",
            "[('함평군', 'NNP'), ('해보면', 'NNP'), ('모', 'NR'), ('평', 'NNM'), ('마을', 'NNG'), ('숲', 'NNG'), ('국가', 'NNG'), ('산림', 'NNG'), ('문화', 'NNG'), ('자산', 'NNG'), ('지정', 'NNG')]\n",
            "[('산업', 'NNG'), ('시설', 'NNG'), ('미세', 'NNG'), ('먼지', 'NNG'), ('절반', 'NNG'), ('으로', 'JKM'), ('줄이', 'VV'), ('는', 'ETD'), ('집진기', 'NNG'), ('기술', 'NNG'), ('개발', 'NNG')]\n",
            "[('신영', 'NNP'), ('증권', 'NNG'), ('삼성전자', 'NNG'), ('2', 'NR'), ('분기', 'NNG'), ('부진', 'NNG'), ('…', 'SE'), ('목표', 'NNG'), ('가', 'JKS'), ('↓', 'SW')]\n",
            "[('AI', 'OL'), ('컬링', 'NNG'), ('로봇', 'NNG'), ('커', 'VV'), ('ㄹ', 'ETD'), ('리', 'NNB'), ('사람', 'NNG'), ('과', 'JKM'), ('첫', 'MDT'), ('대결', 'NNG'), ('서', 'JKM'), ('지', 'VV'), ('었', 'EPT'), ('지만', 'ECE'), ('가능성', 'NNG'), ('확인', 'NNG'), ('종합', 'NNG')]\n",
            "[('류', 'NNG'), ('현진', 'NNP'), ('또', 'MAG'), ('7', 'NR'), ('이닝', 'NNG'), ('무실점', 'NNG'), ('…', 'SE'), ('시즌', 'NNG'), ('9', 'NR'), ('승', 'NNM'), ('·', 'SP'), ('통산', 'NNG'), ('49', 'NR'), ('승', 'NNM'), ('보이', 'VV'), ('ㄴ다', 'ECS'), ('종합', 'NNG')]\n",
            "[('박홍', 'NNG'), ('근', 'NNG'), ('나', 'NP'), ('에', 'JKM'), ('대하', 'VV'), ('ㄴ', 'ETD'), ('공개', 'NNG'), ('조롱', 'NNG'), ('vs', 'OL'), ('오신', 'NNG'), ('환', 'NNG'), ('인지도', 'NNG'), ('높이', 'VV'), ('어', 'ECS'), ('주', 'VXV'), ('ㄴ', 'ETD'), ('것', 'NNB')]\n",
            "[('신간', 'NNG'), ('이', 'MDT'), ('싸움', 'NNG'), ('은', 'JX'), ('우리', 'NP'), ('의', 'JKG'), ('싸움', 'NNG'), ('이', 'VCP'), ('다', 'EFN')]\n",
            "[('연세대', 'NNG'), ('비', 'XPN'), ('대면', 'NNG'), ('강의', 'NNG'), ('실태', 'NNG'), ('조사', 'NNG'), ('…', 'SE'), ('선택적', 'NNG'), ('패스', 'NNG'), ('제', 'NNG'), ('는', 'JX'), ('도입', 'NNG'), ('않', 'VV'), ('기로', 'ECD'), ('종합', 'NNG'), ('2', 'NR'), ('보', 'NNM')]\n",
            "[('나', 'NP'), ('때문', 'NNB'), ('에', 'JKM'), ('경질', 'NNG'), ('차', 'NNG'), ('범', 'XPN'), ('근하', 'NNG'), ('석주', 'NNG'), ('20', 'NR'), ('년', 'NNM'), ('만', 'NNB'), ('의', 'JKG'), ('해후', 'NNG')]\n",
            "[('야당', 'NNG'), ('탄압', 'NNG'), ('수사', 'NNG'), ('관련', 'NNG'), ('기자', 'NNG'), ('회견', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('한국', 'NNG'), ('당', 'NNG'), ('의원', 'NNG'), ('들', 'XSN')]\n",
            "[('SKT', 'OL'), ('대학', 'NNG'), ('·', 'SP'), ('연구', 'NNG'), ('기관', 'NNG'), ('과', 'JC'), ('자율', 'NNG'), ('주행', 'NNG'), ('공동', 'NNG'), ('연구', 'NNG'), ('연합체', 'NNG'), ('발족', 'NNG')]\n",
            "[('檢', 'OH'), ('최', 'NNP'), ('순', 'NNG'), ('실', 'NNG'), ('에', 'JKM'), ('직권', 'NNG'), ('남용', 'NNG'), ('공범', 'NNG'), ('·', 'SP'), ('사기', 'NNG'), ('미수', 'NNG'), ('2', 'NR'), ('개', 'NNM'), ('혐의', 'NNG'), ('적용', 'NNG')]\n",
            "[('평양', 'NNP'), ('정상', 'NNG'), ('회담', 'NNG'), ('평양', 'NNP'), ('시내', 'NNG'), ('카', 'NNG'), ('퍼레이드', 'NNG'), ('하', 'VV'), ('는', 'ETD'), ('남북', 'NNG'), ('정상', 'NNG'), ('차량', 'NNG'), ('행렬', 'NNG')]\n",
            "[('소방', 'NNG'), ('청장', 'NNG'), ('폭염', 'NNG'), ('관련', 'NNG'), ('소방', 'NNG'), ('교육', 'NNG'), ('훈련', 'NNG'), ('기관', 'NNG'), ('현장', 'NNG'), ('점검', 'NNG')]\n",
            "[('한미', 'NNG'), ('정상', 'NNG'), ('핵우산', 'NNG'), ('확장', 'NNG'), ('억제', 'NNG'), ('조치', 'NNG'), ('…', 'SE'), ('안보리', 'NNG'), ('새', 'NNG'), ('결의', 'NNG'), ('등', 'NNB'), ('강력', 'NNG'), ('압박', 'NNG')]\n",
            "[('北', 'OH'), ('36', 'NR'), ('년', 'NNM'), ('만', 'NNB'), ('의', 'JKG'), ('당대회', 'NNG'), ('앞두', 'VV'), ('ㄴ', 'ETD'), ('70', 'NR'), ('일', 'NNM'), ('전투', 'NNG'), ('…', 'SE'), ('부작용', 'NNG'), ('속출', 'NNG')]\n",
            "[('더', 'MAG'), ('민주', 'NNG'), ('한발', 'MAG'), ('무르', 'VV'), ('어서', 'ECD'), ('朴', 'OH'), ('대통령', 'NNG'), ('국회', 'NNG'), ('연설', 'NNG'), ('날짜', 'NNG'), ('수용', 'NNG'), ('종합', 'NNG')]\n",
            "[('이', 'VCP'), ('란', 'ETD'), ('혁명', 'NNG'), ('수비대', 'NNG'), ('테러', 'NNG'), ('조직', 'NNG'), ('지정', 'NNG'), ('에', 'JKM'), ('중동', 'NNP'), ('양분', 'NNG')]\n",
            "[('SKT', 'OL'), ('5', 'NR'), ('G', 'OL'), ('인', 'NNG'), ('빌딩', 'NNG'), ('전용', 'NNG'), ('장비', 'NNG'), ('레이어', 'NNG'), ('스플리터', 'NNG'), ('설치', 'NNG'), ('확대', 'NNG')]\n",
            "[('게시판', 'NNG'), ('유진', 'NNG'), ('투자', 'NNG'), ('증권', 'NNG'), ('모바일', 'NNG'), ('신규', 'NNG'), ('고객', 'NNG'), ('이벤트', 'NNG')]\n",
            "[('문', 'NNG'), ('대통령', 'NNG'), ('국', 'NNG'), ('정지', 'NNG'), ('지도', 'NNG'), ('74', 'NR'), ('%', 'SW'), ('…', 'SE'), ('지난주', 'NNG'), ('보다', 'JKM'), ('3', 'NR'), ('%', 'SW'), ('P', 'OL'), ('상승', 'NNG'), ('갤럽', 'NNG'), ('종합', 'NNG')]\n",
            "[('2018', 'NR'), ('년', 'NNM'), ('지구촌', 'NNG'), ('슬픔', 'NNG'), ('·', 'SP'), ('분노', 'NNG'), ('·', 'SP'), ('두려움', 'NNG'), ('어느', 'MDT'), ('해', 'NNG'), ('보다', 'JKM'), ('크', 'VA'), ('었', 'EPT'), ('다', 'EFN')]\n",
            "[('문', 'NNG'), ('대통령', 'NNG'), ('하', 'VV'), ('ㄴ', 'ETD'), ('러', 'NNP'), ('9', 'NR'), ('개', 'NNM'), ('다리', 'NNG'), ('액션', 'NNG'), ('플랜', 'NNG'), ('9', 'NR'), ('월', 'NNM'), ('동방', 'NNG'), ('포럼', 'NNG'), ('서', 'NNG'), ('서명', 'NNG'), ('기대', 'NNG'), ('속보', 'NNG')]\n",
            "[('디', 'NNG'), ('종', 'NNG'), ('권', 'NNG'), ('창', 'NNG'), ('훈', 'NNG'), ('9', 'NR'), ('일', 'NNM'), ('메스', 'NNG'), ('와', 'JKM'), ('원정', 'NNG'), ('경기', 'NNG'), ('서', 'JKM'), ('데뷔', 'NNG'), ('전', 'NNG'), ('준비', 'NNG')]\n",
            "[('동원', 'NNG'), ('김', 'NNG'), ('스낵', 'NNG'), ('미국', 'NNP'), ('코스트', 'NNG'), ('코', 'NNG'), ('87', 'NR'), ('개', 'NNM'), ('점서', 'NNG'), ('판매', 'NNG')]\n",
            "[('리그', 'NNG'), ('앙서', 'NNG'), ('펄펄', 'MAG'), ('나', 'NP'), ('는', 'JX'), ('석', 'MDN'), ('현준', 'NNG'), ('·', 'SP'), ('권', 'NNG'), ('창', 'NNG'), ('훈', 'NNG'), ('…', 'SE'), ('또', 'MAG'), ('나란히', 'MAG'), ('득점', 'NNG'), ('포', 'NNG'), ('가동', 'NNG')]\n",
            "[('광주', 'NNG'), ('에', 'JKM'), ('대설', 'NNG'), ('주의보', 'NNG'), ('…', 'SE'), ('오전', 'NNG'), ('7', 'NR'), ('시', 'NNM'), ('현재', 'MAG'), ('5.7', 'NR'), ('㎝', 'NNM'), ('쌓이', 'VV'), ('어', 'ECS')]\n",
            "[('폰', 'NNG'), ('파라', 'NNP'), ('하', 'XSV'), ('지', 'ECD'), ('3', 'NR'), ('년', 'NNM'), ('간', 'NNG'), ('포', 'NNG'), ('상금', 'NNG'), ('250', 'NR'), ('억', 'NR'), ('원', 'NNM'), ('넘', 'VV'), ('어', 'ECD')]\n",
            "[('올스타', 'NNG'), ('전', 'NNG'), ('최', 'XPN'), ('준용', 'NNG'), ('하프', 'NNG'), ('라인', 'NNG'), ('슛', 'NNG'), ('관중', 'NNG'), ('도', 'JX'), ('함께', 'MAG'), ('속인', 'NNG'), ('몰래', 'MAG'), ('카메라', 'NNG')]\n",
            "[('이집트', 'NNG'), ('대', 'NNG'), ('박물관', 'NNG'), ('근처', 'NNG'), ('서', 'JKM'), ('폭탄', 'NNG'), ('터지', 'VV'), ('어', 'ECS'), ('…', 'SE'), ('관', 'NNG'), ('광', 'NNG'), ('버스', 'NNG'), ('탑승자', 'NNG'), ('17', 'NR'), ('명', 'NNM'), ('부상', 'NNG')]\n",
            "[('5', 'NR'), ('세트', 'NNG'), ('가빈', 'NNG'), ('이탈', 'NNG'), ('후', 'NNG'), ('역전', 'NNG'), ('…', 'SE'), ('대한', 'NNG'), ('항공', 'NNG'), ('선두', 'NNG'), ('로', 'JKM'), ('반환점', 'NNG'), ('돋', 'VV'), ('아', 'ECD')]\n",
            "[('KT', 'OL'), ('차세대', 'NNG'), ('통신', 'NNG'), ('인프라', 'NNG'), ('혁신', 'NNG'), ('기술', 'NNG'), ('발표', 'NNG')]\n",
            "[('KAIST', 'OL'), ('서', 'JKM'), ('열리', 'VV'), ('ㄴ', 'ETD'), ('저', 'NP'), ('의', 'JKG'), ('1', 'NR'), ('회', 'NNM'), ('국제', 'NNG'), ('AI', 'OL'), ('월드컵', 'NNG')]\n",
            "[('디에이', 'NNG'), ('테크놀로지', 'NNG'), ('최대', 'NNG'), ('주주', 'NNG'), ('에스', 'NNG'), ('모', 'NNG'), ('외', 'NNB'), ('1', 'NR'), ('인', 'NNG'), ('으로', 'JKM'), ('변경', 'NNG')]\n",
            "[('이', 'VCP'), ('란', 'ETD'), ('걸프', 'NNG'), ('상공', 'NNG'), ('서', 'JKM'), ('공격용', 'NNG'), ('드', 'XPN'), ('론', 'NNG'), ('첫', 'MDT'), ('대규모', 'NNG'), ('훈련', 'NNG')]\n",
            "[('지소', 'NNG'), ('미아', 'NNG'), ('종료', 'NNG'), ('정지', 'NNG'), ('1', 'NR'), ('면', 'NNG'), ('머리', 'NNG'), ('기사', 'NNG'), ('로', 'JKM'), ('전하', 'VV'), ('ㄴ', 'ETD'), ('일본', 'NNG'), ('신문', 'NNG'), ('들', 'XSN')]\n",
            "[('삼성', 'NNG'), ('보급', 'NNG'), ('형', 'NNG'), ('개', 'VV'), ('ㄹ', 'ETD'), ('럭', 'UN'), ('시', 'NNG'), ('M', 'OL'), ('시리즈', 'NNG'), ('내년', 'NNG'), ('1', 'NR'), ('분기', 'NNG'), ('출시', 'NNG'), ('전망', 'NNG')]\n",
            "[('이', 'MDT'), ('주아', 'NNG'), ('라이벌', 'NNG'), ('박', 'NNG'), ('은', 'JX'), ('진의', 'NNG'), ('블로킹', 'NNG'), ('의식', 'NNG'), ('이', 'JKC'), ('되', 'VV'), ('더', 'EPT'), ('라고요', 'EFN')]\n",
            "[('그래픽', 'NNG'), ('신혼부부', 'NNG'), ('통계', 'NNG'), ('결과', 'NNG')]\n",
            "[('문', 'NNG'), ('대통령', 'NNG'), ('선거제', 'NNG'), ('개편', 'NNG'), ('이번', 'NNG'), ('에', 'JKM'), ('꼭', 'MAG'), ('하', 'VV'), ('어야', 'ECD'), ('하', 'VV'), ('ㄴ다', 'ECS'), ('종합', 'NNG')]\n",
            "[('국민', 'NNG'), ('은행', 'NNG'), ('안', 'NNG'), ('덕', 'NNG'), ('수', 'XSN'), ('감독', 'NNG'), ('챔프', 'NNP'), ('전', 'NNG'), ('멋있', 'VA'), ('게', 'ECD'), ('준비', 'NNG'), ('하', 'XSV'), ('겠', 'EPT'), ('다', 'EFN')]\n",
            "[('개', 'VV'), ('ㄹ', 'ETD'), ('노트', 'NNG'), ('7', 'NR'), ('리', 'NNB'), ('콜', 'NNG'), ('·', 'SP'), ('교환', 'NNG'), ('후', 'NNG'), ('에', 'JKM'), ('도', 'JX'), ('美', 'OH'), ('·', 'SP'), ('대', 'NNG'), ('만', 'JX'), ('스', 'VV'), ('어', 'ECS'), ('발화', 'NNG'), ('잇따르', 'VV'), ('아', 'ECS'), ('생산', 'NNG'), ('중단', 'NNG'), ('종합', 'NNG')]\n",
            "[('게시판', 'NNG'), ('언론', 'NNG'), ('중재', 'NNG'), ('위원회', 'NNG'), ('제주', 'NNG'), ('사무소', 'NNG'), ('이전', 'NNG')]\n",
            "[('北', 'OH'), ('당국', 'NNG'), ('국토', 'NNG'), ('국', 'NNG'), ('관료', 'NNG'), ('20', 'NR'), ('여', 'NR'), ('명', 'NNM'), ('체포', 'NNG'), ('…', 'SE'), ('홍수피', 'NNG'), ('하', 'XSV'), ('어', 'ECS'), ('책임', 'NNG'), ('전가', 'NNG')]\n",
            "[('여자', 'NNG'), ('농구', 'NNG'), ('신한', 'NNP'), ('은행', 'NNG'), ('국민', 'NNG'), ('은행', 'NNG'), ('꺾', 'VV'), ('고', 'ECE'), ('4', 'NR'), ('연', 'NNG'), ('승', 'NNG'), ('신바람', 'NNG'), ('…', 'SE'), ('스틸', 'NNG'), ('12', 'NR'), ('개', 'NNM')]\n",
            "[('암컷', 'NNG'), ('대게', 'NNG'), ('520', 'NR'), ('마리', 'NNM'), ('보관', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('수산물', 'NNG'), ('판매업자', 'NNG'), ('덜미', 'NNG')]\n",
            "[('산재', 'NNG'), ('처벌', 'NNG'), ('대상', 'NNG'), ('사업주', 'NNG'), ('로', 'JKM'), ('명시', 'NNG'), ('하', 'XSV'), ('어야', 'ECD'), ('…', 'SE'), ('기업', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('매출', 'NNG'), ('따르', 'VV'), ('아', 'ECS'), ('벌금', 'NNG')]\n",
            "[('프로', 'NNG'), ('농구', 'NNG'), ('챔피언', 'NNG'), ('1', 'NR'), ('차', 'NNM'), ('전', 'NNG'), ('부진', 'NNG'), ('SK', 'OL'), ('메이스', 'NNG'), ('동료', 'NNG'), ('선수', 'NNG'), ('들', 'XSN'), ('에', 'JKM'), ('사과', 'NNG')]\n",
            "[('여자', 'NNG'), ('배구', 'NNG'), ('GS', 'OL'), ('칼', 'NNG'), ('텍스', 'NNG'), ('알', 'VV'), ('ㄹ', 'ETD'), ('리', 'NNB'), ('부상', 'NNG'), ('딛', 'VV'), ('고', 'ECE'), ('IBK', 'OL'), ('기업', 'NNG'), ('은행', 'NNG'), ('에', 'JKM'), ('3', 'NR'), ('...', 'SE')]\n",
            "[('NH', 'OL'), ('농협', 'NNG'), ('코스', 'NNG'), ('피', 'NNG'), ('200', 'NR'), ('지수', 'NNG'), ('연동', 'NNG'), ('예금', 'NNG'), ('출시', 'NNG'), ('…', 'SE'), ('최고', 'NNG'), ('연', 'NNG'), ('4.15', 'NR'), ('%', 'SW'), ('수익', 'NNG')]\n",
            "[('권', 'NNG'), ('창', 'NNG'), ('훈', 'NNG'), ('프랑스', 'NNG'), ('디', 'NNG'), ('종', 'NNG'), ('이적', 'NNG'), ('확정', 'NNG'), ('…', 'SE'), ('유럽', 'NNG'), ('진출', 'NNG'), ('꿈', 'NNG'), ('이루', 'VV'), ('었', 'EPT'), ('다', 'EFN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLkC7_cJ-PM_",
        "outputId": "a93b602f-fde2-4573-f7f2-2ad602185de6"
      },
      "source": [
        "print(samples[\"title\"].iloc[0])\n",
        "print(kkma.morphs(samples[\"title\"].iloc[0]))\n",
        "print(kkma.nouns(samples[\"title\"].iloc[0]))\n",
        "print(kkma.pos(samples[\"title\"].iloc[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "사랑이 넘치면서 부재하는 시대에 찾아온 사랑잡가\n",
            "['사랑', '이', '넘치', '면서', '부재', '하', '는', '시대', '에', '찾아오', 'ㄴ', '사랑', '잡가']\n",
            "['사랑', '부재', '시대', '사랑잡가', '잡가']\n",
            "[('사랑', 'NNG'), ('이', 'JKS'), ('넘치', 'VV'), ('면서', 'ECE'), ('부재', 'NNG'), ('하', 'XSV'), ('는', 'ETD'), ('시대', 'NNG'), ('에', 'JKM'), ('찾아오', 'VV'), ('ㄴ', 'ETD'), ('사랑', 'NNG'), ('잡가', 'NNG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j07FZD_uA2nh",
        "outputId": "9fcb74ef-ecc9-4768-8802-6d3d8cf17cf8"
      },
      "source": [
        "s = kkma.pos(samples[\"title\"].iloc[0])\n",
        "s[0][1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NNG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4S5iZVY_sM5",
        "outputId": "284a9a08-ab34-4e7e-b4d9-e5c633dac652"
      },
      "source": [
        "# dacon sample function\n",
        "def clean_text_dacon(text):\n",
        "    text_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \" \", text)\n",
        "    text_clean = re.sub(r'\\d+','',text_clean)\n",
        "    text_clean = re.sub(r\"^\\s+\", '', text_clean) #remove space from start \n",
        "    text_clean = re.sub(r'\\s+$', '', text_clean) #remove space from the end corpus.append(review) return corpus\n",
        "    text_clean = re.sub(r'<[^>]+>','',text_clean) #remove Html tags \n",
        "    return text_clean\n",
        "\n",
        "\n",
        "samples_re = [clean_text_dacon(text) for text in samples[\"title\"].values]\n",
        "\n",
        "for i in range(len(idx_random)):\n",
        "    print(samples_re[i])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "사랑이 넘치면서 부재하는 시대에 찾아온 사랑잡가\n",
            "도쿄 국기관 방문한 트럼프와 아베\n",
            "밸런타인데이에 만나는 예술의전당   시 콘서트\n",
            "이재영 여자 정지석 지석 오빠 진짜 잘하시던데요\n",
            "보 코스피 또   대 폭락해     선 붕괴 마감\n",
            "인권위 스포츠인권 현장조사 학교운동부 훈련실태 등 점검\n",
            "국제사회  인권문제 대응 잰걸음 국내외서 잇단 행사\n",
            "남북미일중 정상급 평창리셉션 참석 펜스 김영남 악수 없었다\n",
            "표류 북한주민 구조 선장 팬티만 입은 채 손 흔들어\n",
            "박병호 결승 밀어내기 볼넷 넥센     연전 위닝시리즈\n",
            "키움증권 올해 면세점 시장     이상 성장 가능성\n",
            "입추에도 전국 폭염 중부 아침 비 경남내륙 오후 소나기\n",
            "제주 고사리 맛도 영양도 만점에 꺾는 재미까지\n",
            "국무부 일각 시리아에 제한적 군사력 사용 주장\n",
            "중국 핵무기는 위협 안 돼       참여 요구 거부\n",
            "월 하순인데 열대야가 제주 열대야   일로 역대  번째\n",
            "베트남전 찾은 박항서 감독 베트남 강합니다\n",
            "지난해 미국 유럽여행에 쓴 돈 줄고 일본 동남아는 늘었다\n",
            "사드보복  개월 방한 동남아 관광객도 줄었다      감소\n",
            "홍콩서   홍콩 인권법안 통과 촉구 대규모 집회\n",
            "문 대통령 아이스하키팀에게 엄지 척\n",
            "점포   개     보스턴 밀워키에 시즌 첫 패배 안겨\n",
            "다음    메일 쓰면서 카톡 이모티콘 사용\n",
            "제  회 방송통신 이용자주간 기념식\n",
            "당대 최고 포수 양의지    억원에   행\n",
            "신간 어둠을 먹는 사람들 거의 완벽에 가까운 사람들\n",
            "전국구스타 류현진   서 교체  이닝  탈삼진  실점\n",
            "실종자 수색하는 소방구조대\n",
            "이란에    억원대 플랜트 기자재 공급계약 체결\n",
            "인치 미만 스마트폰 사라진다    인치가 대세\n",
            "몰래 의자 뒤로 빼 동료 엉덩방아 찧게 한   대 벌금형\n",
            "배구협회 최초로 남녀 국가대표 전임 감독제 시행\n",
            "아이오와 경선 개표 초반 힐러리크루즈  위\n",
            "원주서 중학생  명 코로나   추가 확진 태권도장서 감염\n",
            "몽니 꼼수 두려우면 선거제 패스트트랙 동참 한국당 압박\n",
            "보수표방 단체     다큐 상업광고 사용      검찰 고발\n",
            "경매가     억 추정되는 이중섭 소\n",
            "충주 호암택지지구서  개 아파트 이달 말 동시분양\n",
            "스티브 바라캇 서울 남자 평양 여자 교향곡 버전 선보여\n",
            "독일 강제매춘 종사자 성 매수 땐 징역형 입법 검토\n",
            "글로벌 외환시장서 한국 비중        개국 중   위   위\n",
            "두번째 아트아시아 개막 공모전 첫 수상 젊은 작가들 주목\n",
            "흑해 케르치 해협서 탱크선  척에 화재 최소   명 사망\n",
            "유조선 피격에  드론 격추 끓어오르는 호르무즈 해협\n",
            "재건축 안전진단 강화 여파에 건설 체감경기 악화\n",
            "내일 꽃샘추위 절정 다음 주부터 완연한 봄\n",
            "위클리 스마트 여름철 짜증 나게 하는 땀 그 속에 건강정보 있다\n",
            "북한 낮   시  분 특별 중대보도 예고 핵실험 발표할듯종합\n",
            "관광공사 지정 굿스테이 숙박업소가 성매매 장소 제공\n",
            "함평군 해보면 모평마을숲 국가산림문화자산 지정\n",
            "산업시설 미세먼지 절반으로 줄이는 집진기 기술 개발\n",
            "신영증권 삼성전자  분기 부진 목표가\n",
            "컬링로봇 컬리 사람과 첫 대결서 졌지만 가능성 확인종합\n",
            "류현진 또  이닝 무실점 시즌  승 통산   승 보인다종합\n",
            "박홍근 나에 대한 공개 조롱    오신환 인지도 높여준 것\n",
            "신간 이 싸움은 우리의 싸움이다\n",
            "연세대 비대면강의 실태조사 선택적 패스제는 도입 않기로종합 보\n",
            "나 때문에 경질 차범근하석주   년만의 해후\n",
            "야당탄압 수사관련 기자회견하는 한국당 의원들\n",
            "대학 연구기관과 자율주행 공동연구 연합체 발족\n",
            "최순실에 직권남용 공범 사기미수  개 혐의 적용\n",
            "평양정상회담 평양 시내 카퍼레이드 하는 남북정상 차량 행렬\n",
            "소방청장 폭염관련 소방교육훈련기관 현장점검\n",
            "한미정상 핵우산 확장억제 조치 안보리 새결의 등 강력압박\n",
            "년만의 당대회 앞둔   일 전투 부작용 속출\n",
            "더민주 한발 물러서  대통령 국회연설 날짜 수용종합\n",
            "이란 혁명수비대 테러조직 지정에 중동 양분\n",
            "인빌딩 전용 장비 레이어 스플리터 설치 확대\n",
            "게시판 유진투자증권 모바일 신규 고객 이벤트\n",
            "문 대통령 국정지지도     지난주보다     상승갤럽종합\n",
            "년 지구촌 슬픔 분노 두려움 어느 해보다 컸다\n",
            "문대통령 한러  개 다리 액션플랜  월 동방포럼서 서명 기대속보\n",
            "디종 권창훈  일 메스와 원정경기서 데뷔전 준비\n",
            "동원 김 스낵 미국 코스트코   개점서 판매\n",
            "리그앙서 펄펄 나는 석현준 권창훈 또 나란히 득점포 가동\n",
            "광주에 대설주의보 오전  시 현재      쌓여\n",
            "폰파라치  년간 포상금    억원 넘어\n",
            "올스타전 최준용 하프라인 슛 관중도 함께 속인 몰래카메라\n",
            "이집트대박물관 근처서 폭탄 터져 관광버스 탑승자   명 부상\n",
            "세트 가빈 이탈 후 역전 대한항공 선두로 반환점 돌아\n",
            "차세대 통신 인프라 혁신기술 발표\n",
            "서 열린 제 회 국제    월드컵\n",
            "디에이테크놀로지 최대주주 에스모 외  인으로 변경\n",
            "이란 걸프 상공서 공격용 드론 첫 대규모 훈련\n",
            "지소미아 종료 정지  면 머리기사로 전한 일본 신문들\n",
            "삼성 보급형 갤럭시  시리즈 내년  분기 출시 전망\n",
            "이주아 라이벌 박은진의 블로킹 의식이 되더라고요\n",
            "그래픽 신혼부부 통계 결과\n",
            "문대통령 선거제 개편 이번에 꼭 해야 한다종합\n",
            "국민은행 안덕수 감독 챔프전 멋있게 준비하겠다\n",
            "갤노트  리콜 교환후에도   대만서 발화 잇따라 생산중단종합\n",
            "게시판 언론중재위원회 제주사무소 이전\n",
            "당국 국토국 관료   여명 체포 홍수피해 책임 전가\n",
            "여자농구 신한은행 국민은행 꺾고  연승 신바람 스틸   개\n",
            "암컷 대게    마리 보관한 수산물 판매업자 덜미\n",
            "산재 처벌 대상 사업주로 명시해야 기업엔 매출 따라 벌금\n",
            "프로농구 챔피언  차전 부진    메이스 동료 선수들에 사과\n",
            "여자배구   칼텍스 알리 부상 딛고    기업은행에\n",
            "농협 코스피   지수 연동예금 출시 최고 연       수익\n",
            "권창훈 프랑스 디종 이적 확정 유럽진출 꿈 이뤘다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv-gY7CeAeW1",
        "outputId": "289f83ef-7b80-48af-e8d6-97b0cbc4eb3b"
      },
      "source": [
        "# 명사 + 한자 + 외래어(영문) 추출하는 함수 구현\n",
        "def noun_oh_ol_extract(text):\n",
        "\n",
        "    dict_extract = kkma.pos(text)\n",
        "    list_extract = []\n",
        "\n",
        "    for units in dict_extract:\n",
        "        if (units[1] == \"OH\" or units[1] == \"NNG\" or units[1] == \"OL\"):\n",
        "            list_extract.append(units[0])\n",
        "    return list_extract\n",
        "\n",
        "print(noun_oh_ol_extract(samples[\"title\"].iloc[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사랑', '부재', '시대', '사랑', '잡가']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRAqBPYZB8IP",
        "outputId": "ea940373-93fe-47da-94eb-9be69ec44a9d"
      },
      "source": [
        "# preprocessing \n",
        "\n",
        "import time\n",
        "\n",
        "def preprocessing(df, isTest = False):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    df_copy = df.copy()\n",
        "    texts = df_copy[\"title\"].values\n",
        "\n",
        "    if isTest is False:\n",
        "        labels = df_copy[\"topic_idx\"].values\n",
        "        text_inputs = []\n",
        "        label_inputs = []\n",
        "\n",
        "        for i,text in enumerate(texts):\n",
        "\n",
        "            text_extract = noun_oh_ol_extract(text)\n",
        "\n",
        "            if (len(text_extract) != 0):\n",
        "                text_inputs.append(text_extract)\n",
        "                label_inputs.append(labels[i])\n",
        "\n",
        "            if i % 500 == 0 :\n",
        "                print(\"{}-th text preprocessed\".format(i))\n",
        "\n",
        "        print(\"time for preprocessing: {}s\".format(time.time() - start))\n",
        "        return text_inputs, label_inputs\n",
        "\n",
        "    else:\n",
        "        text_inputs = []\n",
        "\n",
        "        for i,text in enumerate(texts):\n",
        "            text_extract = noun_oh_ol_extract(text)\n",
        "            text_inputs.append(text_extract)\n",
        "\n",
        "        print(\"time for preprocessing: {}s\".format(time.time() - start))\n",
        "        return text_inputs\n",
        "\n",
        "text_preprocessed, labels = preprocessing(df_train, False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0-th text preprocessed\n",
            "500-th text preprocessed\n",
            "1000-th text preprocessed\n",
            "1500-th text preprocessed\n",
            "2000-th text preprocessed\n",
            "2500-th text preprocessed\n",
            "3000-th text preprocessed\n",
            "3500-th text preprocessed\n",
            "4000-th text preprocessed\n",
            "4500-th text preprocessed\n",
            "5000-th text preprocessed\n",
            "5500-th text preprocessed\n",
            "6000-th text preprocessed\n",
            "6500-th text preprocessed\n",
            "7000-th text preprocessed\n",
            "7500-th text preprocessed\n",
            "8000-th text preprocessed\n",
            "8500-th text preprocessed\n",
            "9000-th text preprocessed\n",
            "9500-th text preprocessed\n",
            "10000-th text preprocessed\n",
            "10500-th text preprocessed\n",
            "11000-th text preprocessed\n",
            "11500-th text preprocessed\n",
            "12000-th text preprocessed\n",
            "12500-th text preprocessed\n",
            "13000-th text preprocessed\n",
            "13500-th text preprocessed\n",
            "14000-th text preprocessed\n",
            "14500-th text preprocessed\n",
            "15000-th text preprocessed\n",
            "15500-th text preprocessed\n",
            "16000-th text preprocessed\n",
            "16500-th text preprocessed\n",
            "17000-th text preprocessed\n",
            "17500-th text preprocessed\n",
            "18000-th text preprocessed\n",
            "18500-th text preprocessed\n",
            "19000-th text preprocessed\n",
            "19500-th text preprocessed\n",
            "20000-th text preprocessed\n",
            "20500-th text preprocessed\n",
            "21000-th text preprocessed\n",
            "21500-th text preprocessed\n",
            "22000-th text preprocessed\n",
            "22500-th text preprocessed\n",
            "23000-th text preprocessed\n",
            "23500-th text preprocessed\n",
            "24000-th text preprocessed\n",
            "24500-th text preprocessed\n",
            "25000-th text preprocessed\n",
            "25500-th text preprocessed\n",
            "26000-th text preprocessed\n",
            "26500-th text preprocessed\n",
            "27000-th text preprocessed\n",
            "27500-th text preprocessed\n",
            "28000-th text preprocessed\n",
            "28500-th text preprocessed\n",
            "29000-th text preprocessed\n",
            "29500-th text preprocessed\n",
            "30000-th text preprocessed\n",
            "30500-th text preprocessed\n",
            "31000-th text preprocessed\n",
            "31500-th text preprocessed\n",
            "32000-th text preprocessed\n",
            "32500-th text preprocessed\n",
            "33000-th text preprocessed\n",
            "33500-th text preprocessed\n",
            "34000-th text preprocessed\n",
            "34500-th text preprocessed\n",
            "35000-th text preprocessed\n",
            "35500-th text preprocessed\n",
            "36000-th text preprocessed\n",
            "36500-th text preprocessed\n",
            "37000-th text preprocessed\n",
            "37500-th text preprocessed\n",
            "38000-th text preprocessed\n",
            "38500-th text preprocessed\n",
            "39000-th text preprocessed\n",
            "39500-th text preprocessed\n",
            "40000-th text preprocessed\n",
            "40500-th text preprocessed\n",
            "41000-th text preprocessed\n",
            "41500-th text preprocessed\n",
            "42000-th text preprocessed\n",
            "42500-th text preprocessed\n",
            "43000-th text preprocessed\n",
            "43500-th text preprocessed\n",
            "44000-th text preprocessed\n",
            "44500-th text preprocessed\n",
            "45000-th text preprocessed\n",
            "45500-th text preprocessed\n",
            "time for preprocessing: 617.5511162281036s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfwI6rSeCzI0"
      },
      "source": [
        "# tokenize + train/test split\n",
        "\n",
        "train_len = int(len(df_train) * 0.9)\n",
        "\n",
        "trainSet = text_preprocessed[0:train_len]\n",
        "testSet = text_preprocessed[train_len:]\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(filters = \" \", num_words = 30000)\n",
        "tokenizer.fit_on_texts(trainSet)\n",
        "\n",
        "trainSet_token = tokenizer.texts_to_sequences(trainSet)\n",
        "testSet_token = tokenizer.texts_to_sequences(testSet)\n",
        "\n",
        "trainSet_padding = pad_sequences(trainSet_token, padding = \"post\", dtype = \"int32\")\n",
        "\n",
        "maxlen = trainSet_padding.shape[1]\n",
        "testSet_padding = pad_sequences(testSet_token, padding = \"post\", maxlen = maxlen, dtype = \"int32\")\n",
        "\n",
        "labels_np = np.array(labels)\n",
        "train_labels = labels_np[0:train_len]\n",
        "test_labels = labels_np[train_len:]\n",
        "\n",
        "x_train, y_train = trainSet_padding, train_labels\n",
        "x_test, y_test = testSet_padding, test_labels"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNtxc62YJ6ST",
        "outputId": "5094ab67-81c9-45f6-abf4-fe7f6517b2a2"
      },
      "source": [
        "print(\"훈련 데이터셋: \", x_train.shape)\n",
        "print(\"예측 데이터셋: \", x_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터셋:  (41088, 17)\n",
            "예측 데이터셋:  (4564, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3VmM_QcL0c6Z",
        "outputId": "5f2674f6-ee41-465d-a59d-2277ecb18344"
      },
      "source": [
        "#model parameter\n",
        "vocab_size = tokenizer.num_words\n",
        "maxlen = x_train.shape[1]\n",
        "embed_dim = 64\n",
        "\n",
        "def build_lstm(vocab_size, embed_dim):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape = (maxlen, ), dtype = \"int32\"))\n",
        "\n",
        "    #model.add(tf.keras.layers.Embedding(vocab_size, embed_dim, weights= [embedding_matrix]))\n",
        "    model.add(tf.keras.layers.Embedding(vocab_size, embed_dim))\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, dropout=0.3, recurrent_dropout=0.3, activation = \"relu\", return_sequences = True)))\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, dropout=0.3, recurrent_dropout=0.3, activation = \"tanh\")))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(128))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(7, activation = \"softmax\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "# training\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 32\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 16, verbose = 0)\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(\"transformer_weights.h5\",monitor = \"val_loss\", mode = \"min\", patience = 16, save_best_only=True, save_weights_only = True)\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 8, mode= \"min\", verbose = 0)\n",
        "\n",
        "callbacks_params = [es, mc, lr]\n",
        "\n",
        "# gpu device 수동 할당\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "    model = build_lstm(vocab_size, embed_dim)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 5e-5)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "\n",
        "    model.compile(\n",
        "        #optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
        "        optimizer = optimizer,\n",
        "        loss = loss,\n",
        "        metrics = metric\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # cross validation\n",
        "    n_folds = 3\n",
        "    \n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    cv = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n",
        "\n",
        "    for i, (tra_cv, val_cv) in enumerate(cv.split(x_train, y_train)):\n",
        "        print(\"training model for cv:{}\".format(i+1))\n",
        "        hist = model.fit(x_train[tra_cv,:], y_train[tra_cv], validation_data = (x_train[val_cv,:], y_train[val_cv]), \n",
        "                        epochs = epochs, batch_size = batch_size, verbose = 1,\n",
        "                        callbacks = callbacks_params)\n",
        "    \n",
        "    loss, acc = hist.history[\"loss\"], hist.history[\"accuracy\"]\n",
        "    epoch_axis = range(1, len(loss) + 1)\n",
        "    plt.plot(epoch_axis, loss, \"r\", label = \"train loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print(\"test loss: {}, test acc: {}\".format(eval_loss, eval_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 17, 64)            1920000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 17, 512)           657408    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 4,218,887\n",
            "Trainable params: 4,218,887\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training model for cv:1\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 38s 313ms/step - loss: 1.9390 - accuracy: 0.1734 - val_loss: 1.9334 - val_accuracy: 0.1757\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 16s 292ms/step - loss: 1.9291 - accuracy: 0.1764 - val_loss: 1.9194 - val_accuracy: 0.1769\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 16s 291ms/step - loss: 1.8690 - accuracy: 0.2188 - val_loss: 1.7805 - val_accuracy: 0.2517\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 1.6574 - accuracy: 0.3048 - val_loss: 1.5224 - val_accuracy: 0.3759\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 16s 300ms/step - loss: 1.4795 - accuracy: 0.3561 - val_loss: 1.4093 - val_accuracy: 0.3836\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 1.3901 - accuracy: 0.3834 - val_loss: 1.3610 - val_accuracy: 0.3830\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 15s 287ms/step - loss: 1.3205 - accuracy: 0.4089 - val_loss: 1.2906 - val_accuracy: 0.4655\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 1.2298 - accuracy: 0.4648 - val_loss: 1.1853 - val_accuracy: 0.5303\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 1.0947 - accuracy: 0.5436 - val_loss: 1.0514 - val_accuracy: 0.5854\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.9798 - accuracy: 0.6104 - val_loss: 1.0000 - val_accuracy: 0.6110\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 0.9010 - accuracy: 0.6483 - val_loss: 0.9364 - val_accuracy: 0.6508\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.8310 - accuracy: 0.6842 - val_loss: 0.9062 - val_accuracy: 0.6646\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 0.7775 - accuracy: 0.7079 - val_loss: 0.8801 - val_accuracy: 0.6807\n",
            "Epoch 14/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.7371 - accuracy: 0.7271 - val_loss: 0.8477 - val_accuracy: 0.7031\n",
            "Epoch 15/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 0.6974 - accuracy: 0.7473 - val_loss: 0.8269 - val_accuracy: 0.7116\n",
            "Epoch 16/32\n",
            "54/54 [==============================] - 15s 281ms/step - loss: 0.6607 - accuracy: 0.7657 - val_loss: 0.8259 - val_accuracy: 0.7175\n",
            "Epoch 17/32\n",
            "54/54 [==============================] - 15s 284ms/step - loss: 0.6251 - accuracy: 0.7796 - val_loss: 0.7969 - val_accuracy: 0.7322\n",
            "Epoch 18/32\n",
            "54/54 [==============================] - 15s 284ms/step - loss: 0.6018 - accuracy: 0.7909 - val_loss: 0.7815 - val_accuracy: 0.7415\n",
            "Epoch 19/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.5829 - accuracy: 0.7995 - val_loss: 0.7835 - val_accuracy: 0.7380\n",
            "Epoch 20/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.5560 - accuracy: 0.8102 - val_loss: 0.7792 - val_accuracy: 0.7462\n",
            "Epoch 21/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.5352 - accuracy: 0.8199 - val_loss: 0.7838 - val_accuracy: 0.7437\n",
            "Epoch 22/32\n",
            "54/54 [==============================] - 16s 289ms/step - loss: 0.5200 - accuracy: 0.8253 - val_loss: 0.8159 - val_accuracy: 0.7370\n",
            "Epoch 23/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.5016 - accuracy: 0.8354 - val_loss: 0.7907 - val_accuracy: 0.7492\n",
            "Epoch 24/32\n",
            "54/54 [==============================] - 16s 294ms/step - loss: 0.4894 - accuracy: 0.8367 - val_loss: 0.7945 - val_accuracy: 0.7477\n",
            "Epoch 25/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.4773 - accuracy: 0.8415 - val_loss: 0.7918 - val_accuracy: 0.7492\n",
            "Epoch 26/32\n",
            "54/54 [==============================] - 15s 286ms/step - loss: 0.4628 - accuracy: 0.8500 - val_loss: 0.7898 - val_accuracy: 0.7516\n",
            "Epoch 27/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.4554 - accuracy: 0.8511 - val_loss: 0.7621 - val_accuracy: 0.7581\n",
            "Epoch 28/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.4412 - accuracy: 0.8542 - val_loss: 0.8063 - val_accuracy: 0.7491\n",
            "Epoch 29/32\n",
            "54/54 [==============================] - 16s 288ms/step - loss: 0.4319 - accuracy: 0.8596 - val_loss: 0.8276 - val_accuracy: 0.7484\n",
            "Epoch 30/32\n",
            "54/54 [==============================] - 16s 292ms/step - loss: 0.4275 - accuracy: 0.8616 - val_loss: 0.8090 - val_accuracy: 0.7493\n",
            "Epoch 31/32\n",
            "54/54 [==============================] - 16s 291ms/step - loss: 0.4179 - accuracy: 0.8644 - val_loss: 0.8141 - val_accuracy: 0.7544\n",
            "Epoch 32/32\n",
            "54/54 [==============================] - 16s 291ms/step - loss: 0.4048 - accuracy: 0.8697 - val_loss: 0.8153 - val_accuracy: 0.7527\n",
            "training model for cv:2\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 16s 291ms/step - loss: 0.6059 - accuracy: 0.8038 - val_loss: 0.3616 - val_accuracy: 0.8968\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 16s 292ms/step - loss: 0.5680 - accuracy: 0.8148 - val_loss: 0.3546 - val_accuracy: 0.8982\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 16s 289ms/step - loss: 0.5381 - accuracy: 0.8267 - val_loss: 0.3644 - val_accuracy: 0.8916\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 16s 293ms/step - loss: 0.5214 - accuracy: 0.8325 - val_loss: 0.3545 - val_accuracy: 0.8948\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 16s 298ms/step - loss: 0.5031 - accuracy: 0.8379 - val_loss: 0.3672 - val_accuracy: 0.8893\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4895 - accuracy: 0.8433 - val_loss: 0.3657 - val_accuracy: 0.8880\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 16s 294ms/step - loss: 0.4716 - accuracy: 0.8493 - val_loss: 0.3617 - val_accuracy: 0.8895\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 16s 296ms/step - loss: 0.4542 - accuracy: 0.8546 - val_loss: 0.3832 - val_accuracy: 0.8803\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4467 - accuracy: 0.8591 - val_loss: 0.3807 - val_accuracy: 0.8805\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 16s 299ms/step - loss: 0.4344 - accuracy: 0.8617 - val_loss: 0.3788 - val_accuracy: 0.8811\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4174 - accuracy: 0.8679 - val_loss: 0.3747 - val_accuracy: 0.8824\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4178 - accuracy: 0.8673 - val_loss: 0.3765 - val_accuracy: 0.8815\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 16s 293ms/step - loss: 0.4190 - accuracy: 0.8676 - val_loss: 0.3721 - val_accuracy: 0.8838\n",
            "Epoch 14/32\n",
            "54/54 [==============================] - 16s 296ms/step - loss: 0.4138 - accuracy: 0.8699 - val_loss: 0.3683 - val_accuracy: 0.8843\n",
            "Epoch 15/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4130 - accuracy: 0.8711 - val_loss: 0.3709 - val_accuracy: 0.8833\n",
            "Epoch 16/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4121 - accuracy: 0.8700 - val_loss: 0.3702 - val_accuracy: 0.8835\n",
            "Epoch 17/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4096 - accuracy: 0.8688 - val_loss: 0.3692 - val_accuracy: 0.8849\n",
            "Epoch 18/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4121 - accuracy: 0.8676 - val_loss: 0.3738 - val_accuracy: 0.8826\n",
            "Epoch 19/32\n",
            "54/54 [==============================] - 16s 294ms/step - loss: 0.4031 - accuracy: 0.8720 - val_loss: 0.3729 - val_accuracy: 0.8833\n",
            "Epoch 20/32\n",
            "54/54 [==============================] - 16s 293ms/step - loss: 0.4137 - accuracy: 0.8676 - val_loss: 0.3725 - val_accuracy: 0.8835\n",
            "training model for cv:3\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4668 - accuracy: 0.8489 - val_loss: 0.2615 - val_accuracy: 0.9250\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 16s 292ms/step - loss: 0.4658 - accuracy: 0.8496 - val_loss: 0.2614 - val_accuracy: 0.9251\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 16s 301ms/step - loss: 0.4675 - accuracy: 0.8458 - val_loss: 0.2611 - val_accuracy: 0.9253\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4633 - accuracy: 0.8514 - val_loss: 0.2620 - val_accuracy: 0.9250\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4620 - accuracy: 0.8520 - val_loss: 0.2620 - val_accuracy: 0.9249\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4696 - accuracy: 0.8479 - val_loss: 0.2623 - val_accuracy: 0.9250\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 16s 300ms/step - loss: 0.4639 - accuracy: 0.8499 - val_loss: 0.2623 - val_accuracy: 0.9252\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 16s 293ms/step - loss: 0.4612 - accuracy: 0.8505 - val_loss: 0.2632 - val_accuracy: 0.9246\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4611 - accuracy: 0.8514 - val_loss: 0.2627 - val_accuracy: 0.9255\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 16s 296ms/step - loss: 0.4648 - accuracy: 0.8485 - val_loss: 0.2623 - val_accuracy: 0.9252\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 16s 297ms/step - loss: 0.4647 - accuracy: 0.8504 - val_loss: 0.2633 - val_accuracy: 0.9249\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 16s 290ms/step - loss: 0.4678 - accuracy: 0.8484 - val_loss: 0.2634 - val_accuracy: 0.9249\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 16s 299ms/step - loss: 0.4675 - accuracy: 0.8497 - val_loss: 0.2634 - val_accuracy: 0.9249\n",
            "Epoch 14/32\n",
            "54/54 [==============================] - 16s 298ms/step - loss: 0.4605 - accuracy: 0.8520 - val_loss: 0.2634 - val_accuracy: 0.9249\n",
            "Epoch 15/32\n",
            "54/54 [==============================] - 16s 298ms/step - loss: 0.4632 - accuracy: 0.8518 - val_loss: 0.2633 - val_accuracy: 0.9249\n",
            "Epoch 16/32\n",
            "54/54 [==============================] - 16s 300ms/step - loss: 0.4586 - accuracy: 0.8536 - val_loss: 0.2633 - val_accuracy: 0.9249\n",
            "Epoch 17/32\n",
            "54/54 [==============================] - 16s 296ms/step - loss: 0.4584 - accuracy: 0.8519 - val_loss: 0.2633 - val_accuracy: 0.9249\n",
            "Epoch 18/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4620 - accuracy: 0.8493 - val_loss: 0.2633 - val_accuracy: 0.9250\n",
            "Epoch 19/32\n",
            "54/54 [==============================] - 16s 295ms/step - loss: 0.4625 - accuracy: 0.8511 - val_loss: 0.2634 - val_accuracy: 0.9249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 4s 30ms/step - loss: 0.8471 - accuracy: 0.7198\n",
            "test loss: 0.847121000289917, test acc: 0.7197633385658264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlG58feMKfqr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a45986e8-3912-4f2c-fb56-cf53ec4de0d5"
      },
      "source": [
        "# 양방향 LSTM + attention mechanism\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "# word2vec weight 적용(중복시 생략 가능)\n",
        "import gensim\n",
        "word2vec_model = gensim.models.Word2Vec.load(\"ko.bin\")\n",
        "embedding_matrix = np.zeros((vocab_size, embed_dim), dtype = np.float32)\n",
        "\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    embedding_vector = word2vec_model[word] if word in word2vec_model else None\n",
        "\n",
        "    if idx <= vocab_size:\n",
        "        break\n",
        "        \n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "print(embedding_matrix.shape)\n",
        "\n",
        "def attention_lstm(vocab_size, embed_dim, maxlen):\n",
        "    inputs = tf.keras.layers.Input(shape = (maxlen,), dtype = \"int32\")\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embed_dim, input_length = maxlen, mask_zero = True)(inputs)\n",
        "\n",
        "    x_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.3, recurrent_dropout = 0.3, activation = \"relu\", return_sequences = True))(x)\n",
        "    x_lstm, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.3, recurrent_dropout = 0.3, activation = \"relu\", return_sequences = True, return_state = True))(x_lstm)\n",
        "    state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "    state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "\n",
        "    attention_ban = BahdanauAttention(256)\n",
        "    context_vector, attention_weights = attention_ban(x_lstm, state_h)\n",
        "    x = tf.keras.layers.Dense(128, activation = \"relu\")(context_vector)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    outputs = tf.keras.layers.Dense(7, activation = \"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs, outputs, name = \"attention_lstm\")\n",
        "\n",
        "    return model\n",
        "    \n",
        "\n",
        "\n",
        "# training\n",
        "batch_size = 512\n",
        "epochs = 32\n",
        "\n",
        "# gpu device 수동 할당\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "    # callback parameter\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 12, verbose = 0)\n",
        "    mc = tf.keras.callbacks.ModelCheckpoint(\"attention_lstm_weights.h5\",monitor = \"val_loss\", mode = \"min\", patience = 12, save_best_only = True, save_weights_only = True)\n",
        "    lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 8, mode= \"min\", verbose = 0)\n",
        "\n",
        "    callbacks_params = [es, mc, lr]\n",
        "\n",
        "\n",
        "    model = attention_lstm(vocab_size, embed_dim, maxlen)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 1e-4)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "\n",
        "    #optimizer = \"adam\"\n",
        "    #metric = ['sparse_categorical_accuracy']\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = optimizer,\n",
        "        loss = loss,\n",
        "        metrics = metric\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # cross validation\n",
        "    n_folds = 3\n",
        "\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    cv = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n",
        "\n",
        "    for i, (tra_cv, val_cv) in enumerate(cv.split(x_train, y_train)):\n",
        "        print(\"training model for cv:{}\".format(i+1))\n",
        "        hist = model.fit(x_train[tra_cv,:], y_train[tra_cv], validation_data = (x_train[val_cv,:], y_train[val_cv]), \n",
        "                        epochs = epochs, batch_size = batch_size, verbose = 1,\n",
        "                        callbacks = callbacks_params)\n",
        "\n",
        "    loss, acc = hist.history[\"loss\"], hist.history[\"accuracy\"]\n",
        "    epoch_axis = range(1, len(loss) + 1)\n",
        "    plt.plot(epoch_axis, loss, \"r\", label = \"train loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print(\"test loss: {}, test acc: {}\".format(eval_loss, eval_acc))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 64)\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"attention_lstm\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 17, 64)       1920000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 17, 256)      197632      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 17, 256), (N 394240      bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional_3[0][1]            \n",
            "                                                                 bidirectional_3[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "bahdanau_attention (BahdanauAtt ((None, 256), (None, 131841      bidirectional_3[0][0]            \n",
            "                                                                 concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          32896       bahdanau_attention[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 7)            903         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,677,512\n",
            "Trainable params: 2,677,512\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "training model for cv:1\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 35s 378ms/step - loss: 1.9435 - accuracy: 0.1738 - val_loss: 1.9396 - val_accuracy: 0.1757\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 1.9233 - accuracy: 0.1753 - val_loss: 1.8935 - val_accuracy: 0.1757\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 1.8456 - accuracy: 0.1823 - val_loss: 1.7838 - val_accuracy: 0.2362\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 19s 359ms/step - loss: 1.7172 - accuracy: 0.2606 - val_loss: 1.6639 - val_accuracy: 0.3413\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 18s 342ms/step - loss: 1.5911 - accuracy: 0.3205 - val_loss: 1.5171 - val_accuracy: 0.3442\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 1.4138 - accuracy: 0.3931 - val_loss: 1.3300 - val_accuracy: 0.4515\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 19s 344ms/step - loss: 1.2146 - accuracy: 0.4880 - val_loss: 1.1867 - val_accuracy: 0.5211\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 1.0924 - accuracy: 0.5446 - val_loss: 1.1170 - val_accuracy: 0.5585\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.9950 - accuracy: 0.5915 - val_loss: 1.0602 - val_accuracy: 0.5897\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.9209 - accuracy: 0.6294 - val_loss: 1.0154 - val_accuracy: 0.6158\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.8514 - accuracy: 0.6630 - val_loss: 0.9777 - val_accuracy: 0.6360\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.7831 - accuracy: 0.6980 - val_loss: 0.9313 - val_accuracy: 0.6669\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 18s 341ms/step - loss: 0.7227 - accuracy: 0.7255 - val_loss: 0.9061 - val_accuracy: 0.6741\n",
            "Epoch 14/32\n",
            "54/54 [==============================] - 18s 336ms/step - loss: 0.6657 - accuracy: 0.7452 - val_loss: 0.8973 - val_accuracy: 0.6874\n",
            "Epoch 15/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.6253 - accuracy: 0.7622 - val_loss: 0.8935 - val_accuracy: 0.6859\n",
            "Epoch 16/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.5909 - accuracy: 0.7755 - val_loss: 0.8852 - val_accuracy: 0.6999\n",
            "Epoch 17/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.5684 - accuracy: 0.7853 - val_loss: 0.8724 - val_accuracy: 0.7087\n",
            "Epoch 18/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.5372 - accuracy: 0.8032 - val_loss: 0.8694 - val_accuracy: 0.7144\n",
            "Epoch 19/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.5068 - accuracy: 0.8183 - val_loss: 0.9882 - val_accuracy: 0.7253\n",
            "Epoch 20/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.4828 - accuracy: 0.8348 - val_loss: 0.8892 - val_accuracy: 0.7305\n",
            "Epoch 21/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.4620 - accuracy: 0.8466 - val_loss: 0.8930 - val_accuracy: 0.7359\n",
            "Epoch 22/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.4331 - accuracy: 0.8596 - val_loss: 0.9005 - val_accuracy: 0.7371\n",
            "Epoch 23/32\n",
            "54/54 [==============================] - 18s 334ms/step - loss: 0.4382 - accuracy: 0.8605 - val_loss: 0.8834 - val_accuracy: 0.7384\n",
            "Epoch 24/32\n",
            "54/54 [==============================] - 18s 336ms/step - loss: 0.4040 - accuracy: 0.8726 - val_loss: 0.8905 - val_accuracy: 0.7428\n",
            "Epoch 25/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.3888 - accuracy: 0.8772 - val_loss: 0.9085 - val_accuracy: 0.7436\n",
            "Epoch 26/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.3761 - accuracy: 0.8819 - val_loss: 0.9061 - val_accuracy: 0.7431\n",
            "Epoch 27/32\n",
            "54/54 [==============================] - 18s 336ms/step - loss: 0.3600 - accuracy: 0.8892 - val_loss: 0.9104 - val_accuracy: 0.7445\n",
            "Epoch 28/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.3609 - accuracy: 0.8880 - val_loss: 0.9127 - val_accuracy: 0.7450\n",
            "Epoch 29/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.3511 - accuracy: 0.8922 - val_loss: 0.9189 - val_accuracy: 0.7446\n",
            "Epoch 30/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.3515 - accuracy: 0.8925 - val_loss: 0.9210 - val_accuracy: 0.7446\n",
            "training model for cv:2\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.6521 - accuracy: 0.8084 - val_loss: 0.2989 - val_accuracy: 0.9186\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 18s 334ms/step - loss: 0.6176 - accuracy: 0.8088 - val_loss: 0.3093 - val_accuracy: 0.9188\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 18s 330ms/step - loss: 0.6050 - accuracy: 0.8123 - val_loss: 0.3159 - val_accuracy: 0.9192\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 18s 327ms/step - loss: 0.5941 - accuracy: 0.8166 - val_loss: 0.3188 - val_accuracy: 0.9194\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 18s 327ms/step - loss: 0.5862 - accuracy: 0.8173 - val_loss: 0.3231 - val_accuracy: 0.9185\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 18s 327ms/step - loss: 0.5881 - accuracy: 0.8172 - val_loss: 0.3248 - val_accuracy: 0.9181\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 18s 331ms/step - loss: 0.5805 - accuracy: 0.8179 - val_loss: 0.3258 - val_accuracy: 0.9182\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 18s 329ms/step - loss: 0.5753 - accuracy: 0.8213 - val_loss: 0.3243 - val_accuracy: 0.9186\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 18s 331ms/step - loss: 0.5715 - accuracy: 0.8233 - val_loss: 0.3254 - val_accuracy: 0.9179\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 18s 329ms/step - loss: 0.5673 - accuracy: 0.8247 - val_loss: 0.3254 - val_accuracy: 0.9180\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 18s 329ms/step - loss: 0.5685 - accuracy: 0.8213 - val_loss: 0.3255 - val_accuracy: 0.9179\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.5640 - accuracy: 0.8243 - val_loss: 0.3256 - val_accuracy: 0.9176\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 18s 333ms/step - loss: 0.5636 - accuracy: 0.8276 - val_loss: 0.3256 - val_accuracy: 0.9174\n",
            "training model for cv:3\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.5794 - accuracy: 0.8189 - val_loss: 0.3026 - val_accuracy: 0.9246\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.5726 - accuracy: 0.8218 - val_loss: 0.3026 - val_accuracy: 0.9246\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.5781 - accuracy: 0.8208 - val_loss: 0.3031 - val_accuracy: 0.9245\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 18s 341ms/step - loss: 0.5743 - accuracy: 0.8216 - val_loss: 0.3032 - val_accuracy: 0.9245\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.5769 - accuracy: 0.8197 - val_loss: 0.3031 - val_accuracy: 0.9245\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.5744 - accuracy: 0.8214 - val_loss: 0.3028 - val_accuracy: 0.9244\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.5755 - accuracy: 0.8222 - val_loss: 0.3034 - val_accuracy: 0.9244\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.5744 - accuracy: 0.8225 - val_loss: 0.3033 - val_accuracy: 0.9244\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.5718 - accuracy: 0.8219 - val_loss: 0.3034 - val_accuracy: 0.9244\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.5747 - accuracy: 0.8207 - val_loss: 0.3034 - val_accuracy: 0.9243\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.5775 - accuracy: 0.8204 - val_loss: 0.3034 - val_accuracy: 0.9244\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.5773 - accuracy: 0.8189 - val_loss: 0.3035 - val_accuracy: 0.9244\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 18s 334ms/step - loss: 0.5766 - accuracy: 0.8198 - val_loss: 0.3035 - val_accuracy: 0.9244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 4s 25ms/step - loss: 0.9376 - accuracy: 0.6950\n",
            "test loss: 0.9376471042633057, test acc: 0.695004403591156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OLSZUKBXNuJI",
        "outputId": "81df4215-3dcc-4ef4-806b-e4608edbf78b"
      },
      "source": [
        "# transformer를 이용한 모델\n",
        "\n",
        "# Transformer block\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
        "        self.ffn = tf.keras.models.Sequential(\n",
        "            [tf.keras.layers.Dense(ff_dim, activation = \"relu\"), tf.keras.layers.Dense(embed_dim)]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.training = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=self.training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=self.training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = self.maxlen\n",
        "        #positions = tf.range(start=0, limit = maxlen, delta=1)\n",
        "        positions = tf.range(start=0, limit = maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions    \n",
        "\n",
        "class Encoder(tf.keras.models.Model):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.frontLayer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "        self.backLayer = TransformerBlock(embed_dim, num_heads, ff_dim, rate)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.frontLayer(inputs)\n",
        "        x = self.backLayer(x)\n",
        "        return x\n",
        "\n",
        "def transformer_classification(embed_dim, num_heads, ff_dim, rate, maxlen, units):\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape = (maxlen,), dtype = \"int32\")\n",
        "    encoder = Encoder(maxlen, vocab_size, embed_dim, num_heads, ff_dim, rate = 0.3)\n",
        "\n",
        "    x = encoder(inputs)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(7, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name = \"transformer\")\n",
        "\n",
        "    return encoder, model\n",
        "\n",
        "# training\n",
        "batch_size = 512\n",
        "epochs = 32\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 12, verbose = 0)\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(\"transformer_weights.h5\",monitor = \"val_loss\", mode = \"min\", patience = 12, save_best_only=True, save_weights_only = True)\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 8, mode= \"min\", verbose = 0)\n",
        "\n",
        "callbacks_params = [es, mc, lr]\n",
        "\n",
        "# gpu device 수동 할당\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "    # model parameter\n",
        "    vocab_size = tokenizer.num_words\n",
        "    maxlen = x_train.shape[1]\n",
        "    embed_dim = 64\n",
        "    num_heads = 16\n",
        "    ff_dim = 256\n",
        "    rate = 0.3\n",
        "    units = 128\n",
        "\n",
        "    encoder, model = transformer_classification(embed_dim, num_heads, ff_dim, rate, maxlen, units)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 1e-4)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = optimizer,\n",
        "        loss = loss,\n",
        "        metrics = metric\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # cross validation\n",
        "    n_folds = 3\n",
        "\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    cv = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n",
        "\n",
        "    for i, (tra_cv, val_cv) in enumerate(cv.split(x_train, y_train)):\n",
        "        print(\"training model for cv:{}\".format(i+1))\n",
        "        hist = model.fit(x_train[tra_cv,:], y_train[tra_cv], validation_data = (x_train[val_cv,:], y_train[val_cv]), \n",
        "                        epochs = epochs, batch_size = batch_size, verbose = 1,\n",
        "                        callbacks = callbacks_params)\n",
        "\n",
        "    loss, acc = hist.history[\"loss\"], hist.history[\"accuracy\"]\n",
        "    epoch_axis = range(1, len(loss) + 1)\n",
        "    plt.plot(epoch_axis, loss, \"r\", label = \"train loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print(\"test loss: {}, test acc: {}\".format(eval_loss, eval_acc))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 17)]              0         \n",
            "_________________________________________________________________\n",
            "encoder_1 (Encoder)          (None, 17, 64)            2219712   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 2,245,447\n",
            "Trainable params: 2,245,447\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training model for cv:1\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 3s 29ms/step - loss: 1.9171 - accuracy: 0.2051 - val_loss: 1.8586 - val_accuracy: 0.3096\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 1.7801 - accuracy: 0.3477 - val_loss: 1.6006 - val_accuracy: 0.4741\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 1.3768 - accuracy: 0.5375 - val_loss: 1.0802 - val_accuracy: 0.6445\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.8986 - accuracy: 0.7043 - val_loss: 0.7726 - val_accuracy: 0.7357\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6445 - accuracy: 0.7896 - val_loss: 0.6829 - val_accuracy: 0.7690\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.5186 - accuracy: 0.8347 - val_loss: 0.6301 - val_accuracy: 0.7869\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.4373 - accuracy: 0.8627 - val_loss: 0.6223 - val_accuracy: 0.7932\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3735 - accuracy: 0.8837 - val_loss: 0.6241 - val_accuracy: 0.7993\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3277 - accuracy: 0.9000 - val_loss: 0.6158 - val_accuracy: 0.8034\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.2821 - accuracy: 0.9145 - val_loss: 0.6295 - val_accuracy: 0.8051\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.2503 - accuracy: 0.9236 - val_loss: 0.6417 - val_accuracy: 0.8073\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.2228 - accuracy: 0.9336 - val_loss: 0.6656 - val_accuracy: 0.8013\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.1968 - accuracy: 0.9414 - val_loss: 0.6886 - val_accuracy: 0.8034\n",
            "Epoch 14/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1752 - accuracy: 0.9484 - val_loss: 0.7178 - val_accuracy: 0.8025\n",
            "Epoch 15/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1572 - accuracy: 0.9541 - val_loss: 0.7414 - val_accuracy: 0.8002\n",
            "Epoch 16/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1451 - accuracy: 0.9579 - val_loss: 0.7701 - val_accuracy: 0.7996\n",
            "Epoch 17/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1270 - accuracy: 0.9634 - val_loss: 0.7982 - val_accuracy: 0.7983\n",
            "Epoch 18/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1097 - accuracy: 0.9691 - val_loss: 0.8011 - val_accuracy: 0.7989\n",
            "Epoch 19/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.1066 - accuracy: 0.9706 - val_loss: 0.8086 - val_accuracy: 0.7980\n",
            "Epoch 20/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1060 - accuracy: 0.9709 - val_loss: 0.8137 - val_accuracy: 0.7978\n",
            "Epoch 21/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.1023 - accuracy: 0.9725 - val_loss: 0.8123 - val_accuracy: 0.7986\n",
            "training model for cv:2\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.4525 - accuracy: 0.8828 - val_loss: 0.0914 - val_accuracy: 0.9765\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.4211 - accuracy: 0.8869 - val_loss: 0.0953 - val_accuracy: 0.9767\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3907 - accuracy: 0.8897 - val_loss: 0.0998 - val_accuracy: 0.9745\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3769 - accuracy: 0.8940 - val_loss: 0.1049 - val_accuracy: 0.9744\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3612 - accuracy: 0.8955 - val_loss: 0.1079 - val_accuracy: 0.9747\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3538 - accuracy: 0.8973 - val_loss: 0.1119 - val_accuracy: 0.9739\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3452 - accuracy: 0.8988 - val_loss: 0.1142 - val_accuracy: 0.9736\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3388 - accuracy: 0.9011 - val_loss: 0.1173 - val_accuracy: 0.9723\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3314 - accuracy: 0.9025 - val_loss: 0.1168 - val_accuracy: 0.9718\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3281 - accuracy: 0.9052 - val_loss: 0.1174 - val_accuracy: 0.9720\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3264 - accuracy: 0.9056 - val_loss: 0.1179 - val_accuracy: 0.9714\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3279 - accuracy: 0.9034 - val_loss: 0.1172 - val_accuracy: 0.9720\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3263 - accuracy: 0.9036 - val_loss: 0.1182 - val_accuracy: 0.9715\n",
            "training model for cv:3\n",
            "Epoch 1/32\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 0.3338 - accuracy: 0.9015 - val_loss: 0.0976 - val_accuracy: 0.9782\n",
            "Epoch 2/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3318 - accuracy: 0.9009 - val_loss: 0.0984 - val_accuracy: 0.9782\n",
            "Epoch 3/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3357 - accuracy: 0.9029 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 4/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3324 - accuracy: 0.9023 - val_loss: 0.0995 - val_accuracy: 0.9782\n",
            "Epoch 5/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3318 - accuracy: 0.9011 - val_loss: 0.0989 - val_accuracy: 0.9782\n",
            "Epoch 6/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3327 - accuracy: 0.9021 - val_loss: 0.0995 - val_accuracy: 0.9774\n",
            "Epoch 7/32\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3302 - accuracy: 0.9035 - val_loss: 0.0987 - val_accuracy: 0.9788\n",
            "Epoch 8/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3317 - accuracy: 0.9025 - val_loss: 0.0996 - val_accuracy: 0.9788\n",
            "Epoch 9/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3316 - accuracy: 0.9017 - val_loss: 0.0986 - val_accuracy: 0.9787\n",
            "Epoch 10/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3299 - accuracy: 0.9032 - val_loss: 0.0995 - val_accuracy: 0.9786\n",
            "Epoch 11/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3293 - accuracy: 0.9044 - val_loss: 0.0982 - val_accuracy: 0.9793\n",
            "Epoch 12/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3315 - accuracy: 0.9017 - val_loss: 0.0989 - val_accuracy: 0.9779\n",
            "Epoch 13/32\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3300 - accuracy: 0.9027 - val_loss: 0.0995 - val_accuracy: 0.9785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.7800\n",
            "test loss: 0.6903169751167297, test acc: 0.7800175547599792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yfNvIeMONcl"
      },
      "source": [
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q -U tf-models-official\n",
        "!pip install -U tfds-nightly\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp import optimization\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LuNrpIbvzZ0R",
        "outputId": "91ec8b29-f9fd-41ab-ad1c-7d76d0667eb9"
      },
      "source": [
        "# switch transformer\n",
        "\n",
        "# Transformer block\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ffn, rate = 0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
        "        self.ffn = ffn\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.training = True\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training= training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training = training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = self.maxlen\n",
        "        #positions = tf.range(start=0, limit = maxlen, delta=1)\n",
        "        positions = tf.range(start=0, limit = maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions    \n",
        "\n",
        "\n",
        "# load balanced loss\n",
        "def load_balanced_loss(router_probs, expert_mask):\n",
        "    num_experts = tf.shape(expert_mask)[-1]\n",
        "    density = tf.reduce_mean(expert_mask, axis = 0)\n",
        "    density_proxy = tf.reduce_mean(router_probs, axis = 0)\n",
        "    loss = tf.reduce_mean(density_proxy * density) * tf.cast((num_experts ** 2), tf.float32)\n",
        "\n",
        "    return loss\n",
        "\n",
        "class Router(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_experts, expert_capacity):\n",
        "        super(Router, self).__init__()\n",
        "        self.route = tf.keras.layers.Dense(num_experts)\n",
        "        self.expert_capacity = expert_capacity\n",
        "        self.num_experts = num_experts\n",
        "    def call(self, inputs, training = False):\n",
        "        router_logits = self.route(inputs)\n",
        "        #router_logits = tf.reshape(router_logits,shape = [-1, router_logits.shape[1]])\n",
        "\n",
        "        \n",
        "        if training:\n",
        "            router_logits += tf.random.uniform(shape = router_logits.shape, minval = 0.9, maxval = 1.1)\n",
        "        \n",
        "\n",
        "        router_probs = tf.keras.activations.softmax(router_logits, axis = 1)\n",
        "        expert_gate, expert_index = tf.math.top_k(router_probs, k = 1)\n",
        "        expert_mask = tf.one_hot(expert_index, depth = self.num_experts)\n",
        "        aux_loss = load_balanced_loss(router_probs, expert_mask)\n",
        "\n",
        "        self.add_loss(aux_loss)\n",
        "\n",
        "        position_in_expert = tf.cast(tf.math.cumsum(expert_mask, axis = 0) * expert_mask, tf.dtypes.int32)\n",
        "        expert_mask *= tf.cast(\n",
        "            tf.math.less(\n",
        "                tf.cast(position_in_expert, tf.dtypes.int32), self.expert_capacity\n",
        "                ), tf.dtypes.float32)\n",
        "        expert_mask_flat = tf.reduce_sum(expert_mask, axis = -1)\n",
        "        expert_gate *= expert_mask_flat\n",
        "\n",
        "        # Create binary dispatch_tensor [tokens_per_batch, num_experts, expert_capacity]\n",
        "        # that is 1 if the token gets routed to the corresponding expert.\n",
        "\n",
        "        combined_tensor = tf.expand_dims(\n",
        "            expert_gate * expert_mask_flat * tf.squeeze(tf.one_hot(expert_index, depth=self.num_experts),1),-1,) * tf.squeeze(tf.one_hot(position_in_expert, depth=self.expert_capacity), 1)\n",
        "      \n",
        "        dispatch_tensor = tf.cast(combined_tensor, tf.dtypes.float32)\n",
        "\n",
        "        return dispatch_tensor, combined_tensor\n",
        "\n",
        "def create_feedforward_network(ff_dim, name=None):\n",
        "    return tf.keras.models.Sequential([\n",
        "                                       tf.keras.layers.Dense(ff_dim, activation=\"relu\"), \n",
        "                                       tf.keras.layers.Dense(ff_dim)], name=name)\n",
        "\n",
        "class Switch(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_experts, embed_dim, num_tokens_per_batch, capacity_factor=1):\n",
        "        super(Switch, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.embed_dim = embed_dim\n",
        "        self.experts = [\n",
        "            create_feedforward_network(embed_dim) for _ in range(num_experts)\n",
        "        ]\n",
        "        self.expert_capacity = num_tokens_per_batch // self.num_experts\n",
        "        self.router = Router(self.num_experts, self.expert_capacity)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        num_tokens_per_example = tf.shape(inputs)[1]\n",
        "        num_tokens_per_batch = num_tokens_per_example * batch_size\n",
        "\n",
        "        inputs = tf.reshape(inputs, [num_tokens_per_batch, self.embed_dim])\n",
        "\n",
        "        dispatch_tensor, combine_tensor = self.router(inputs)\n",
        "        expert_inputs = tf.einsum(\"ab,acd->cdb\", inputs, dispatch_tensor)\n",
        "        expert_inputs = tf.reshape(\n",
        "            expert_inputs, [self.num_experts, self.expert_capacity, self.embed_dim]\n",
        "        )\n",
        "        expert_input_list = tf.unstack(expert_inputs, axis=0)\n",
        "        expert_output_list = [\n",
        "            self.experts[idx](expert_input)\n",
        "            for idx, expert_input in enumerate(expert_input_list)\n",
        "        ]\n",
        "        expert_outputs = tf.stack(expert_output_list, axis=1)\n",
        "        expert_outputs_combined = tf.einsum(\n",
        "            \"abc,xba->xc\", expert_outputs, combine_tensor\n",
        "        )\n",
        "        outputs = tf.reshape(\n",
        "            expert_outputs_combined,\n",
        "            [batch_size, num_tokens_per_example, self.embed_dim],\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "\n",
        "def switch_transformer(num_experts, embed_dim, num_tokkens_per_batch, ff_dim, num_heads, maxlen, vocab_size, rate, units):\n",
        "\n",
        "    switch = Switch(num_experts, embed_dim, num_tokens_per_batch)\n",
        "    transformer_block = TransformerBlock(ff_dim, num_heads, switch, rate)\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=(maxlen,), batch_size = batch_size)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "\n",
        "    x = embedding_layer(inputs)\n",
        "    x = transformer_block(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(rate)(x)\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(rate)(x)\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(7, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name = \"switch_transformer\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# training\n",
        "batch_size = 512\n",
        "epochs = 32\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 12, verbose = 0)\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(\"switch_transformer_weights.h5\",monitor = \"val_loss\", mode = \"min\", patience = 12, save_best_only=True, save_weights_only = True)\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 8, mode= \"min\", verbose = 0)\n",
        "\n",
        "callbacks_params = [es, mc, lr]\n",
        "\n",
        "# gpu device 수동 할당\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "    # model parameter\n",
        "    vocab_size = tokenizer.num_words\n",
        "    maxlen = x_train.shape[1]\n",
        "    num_tokkens_per_batch = (batch_size * maxlen)\n",
        "    num_experts = 16\n",
        "    embed_dim = 64\n",
        "    num_heads = 16\n",
        "    ff_dim = 64\n",
        "    rate = 0.3\n",
        "    units = 128\n",
        "\n",
        "    model = switch_transformer(num_experts, embed_dim, num_tokkens_per_batch, ff_dim, num_heads, maxlen, vocab_size, rate, units)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 1e-4)\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = optimizer,\n",
        "        loss = loss,\n",
        "        metrics = metric\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # cross validation\n",
        "    n_folds = 3\n",
        "\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    cv = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n",
        "\n",
        "    \n",
        "\n",
        "    for i, (tra_cv, val_cv) in enumerate(cv.split(x_train, y_train)):\n",
        "        print(\"training model for cv:{}\".format(i+1))\n",
        "        hist = model.fit(x_train[tra_cv,:], y_train[tra_cv], validation_data = (x_train[val_cv,:], y_train[val_cv]), \n",
        "                        epochs = epochs, batch_size = batch_size, verbose = 1,\n",
        "                        callbacks = callbacks_params)\n",
        "    \n",
        "\n",
        "    #hist = model.fit(x_train, y_train, verbose = 1, epochs = epochs, batch_size = batch_size)\n",
        "\n",
        "    loss, acc = hist.history[\"loss\"], hist.history[\"accuracy\"]\n",
        "    epoch_axis = range(1, len(loss) + 1)\n",
        "    plt.plot(epoch_axis, loss, \"r\", label = \"train loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show() \n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print(\"test loss: {}, test acc: {}\".format(eval_loss, eval_acc))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"switch_transformer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(512, 17)]               0         \n",
            "_________________________________________________________________\n",
            "token_and_position_embedding (512, 17, 64)             1921088   \n",
            "_________________________________________________________________\n",
            "transformer_block_22 (Transf (512, 17, 64)             399696    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_14  (512, 64)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (512, 64)                 0         \n",
            "_________________________________________________________________\n",
            "dense_749 (Dense)            (512, 128)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (512, 128)                0         \n",
            "_________________________________________________________________\n",
            "dense_750 (Dense)            (512, 128)                16512     \n",
            "_________________________________________________________________\n",
            "dense_751 (Dense)            (512, 7)                  903       \n",
            "=================================================================\n",
            "Total params: 2,346,519\n",
            "Trainable params: 2,346,519\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training model for cv:1\n",
            "Epoch 1/32\n",
            "53/54 [============================>.] - ETA: 0s - loss: 2.9768 - accuracy: 0.1711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-d7e16351efe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m         hist = model.fit(x_train[tra_cv,:], y_train[tra_cv], validation_data = (x_train[val_cv,:], y_train[val_cv]), \n\u001b[1;32m    204\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                         callbacks = callbacks_params)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  Input to reshape is a tensor with 4352 values, but the requested shape has 8704\n\t [[node gradient_tape/switch_transformer/token_and_position_embedding_20/embedding_42/embedding_lookup/Reshape_1 (defined at <ipython-input-58-d7e16351efe2>:205) ]]\n  (1) Invalid argument:  Input to reshape is a tensor with 4352 values, but the requested shape has 8704\n\t [[node gradient_tape/switch_transformer/token_and_position_embedding_20/embedding_42/embedding_lookup/Reshape_1 (defined at <ipython-input-58-d7e16351efe2>:205) ]]\n\t [[Adam/Cast_7/ReadVariableOp/_10]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_147212]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/switch_transformer/token_and_position_embedding_20/embedding_42/embedding_lookup/Reshape_1:\n switch_transformer/token_and_position_embedding_20/embedding_42/Cast (defined at <ipython-input-58-d7e16351efe2>:35)\n\nInput Source operations connected to node gradient_tape/switch_transformer/token_and_position_embedding_20/embedding_42/embedding_lookup/Reshape_1:\n switch_transformer/token_and_position_embedding_20/embedding_42/Cast (defined at <ipython-input-58-d7e16351efe2>:35)\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekr0hHniAziM",
        "outputId": "3964aa5f-dce8-4b36-e5b6-cd9122dec2e1"
      },
      "source": [
        "8704 / 17"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uDTApA-63yI",
        "outputId": "7e9dd889-de1e-4680-c9a0-335fdf0dc5e1"
      },
      "source": [
        "# torch를 이용한 kobert 모델\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp \n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 # 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "\n",
        "output.clear()\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model()\n",
        "\n",
        "# cuda 사용 불사기 gpu로..\n",
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()\n",
        "\n",
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer() # kobert 전용 토크나이저\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset,bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "        \n",
        "        self.sentences = [transform(i) for i in dataset[\"title\"]]\n",
        "        self.labels = [i for i in dataset[\"topic_idx\"]]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "\n",
        "# Setting parameters\n",
        "max_len = 32 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 512\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 8\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainSet, testSet = train_test_split(df_train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# dataset 구축\n",
        "data_train = BERTDataset(trainSet, tok, max_len, True, False)\n",
        "data_test = BERTDataset(testSet, tok, max_len, True, False)\n",
        "\n",
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, bert, hidden_size = 768, num_classes = 7, dr_rate = None,params = None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "\n",
        "        return self.classifier(out)\n",
        "      \n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "\n",
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "  \n",
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfX4r7dEw79"
      },
      "source": [
        "# kobert model using tensorflow\n",
        "!git clone https://github.com/google-research/bert\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "    log.warning('Not connected to TPU runtime')\n",
        "    USE_TPU = False\n",
        "\n",
        "MAX_SEQ_LENGTH = 128 \n",
        "MASKED_LM_PROB = 0.15 \n",
        "MAX_PREDICTIONS = 20 \n",
        "DO_LOWER_CASE = True \n",
        "PROCESSES = 4 \n",
        "PRETRAINING_DIR = \"pretraining_data\" \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJbUtY4baq0S",
        "outputId": "55e8ffda-082a-4e0f-e5b0-ecb3e16ef711"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 7, n_jobs = -1)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "x_train_knn, y_train_knn = flatten(encoder(x_train)), y_train\n",
        "x_test_knn, y_test_knn = flatten(encoder(x_test)), y_test\n",
        "\n",
        "knn.fit(x_train_knn, y_train_knn)\n",
        "eval = knn.score(x_test_knn, y_test_knn)\n",
        "\n",
        "print(eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7082466323513307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLP0XQA4XjlN",
        "outputId": "35993396-f624-42b8-d30e-02fc025422b0"
      },
      "source": [
        "#svc model\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(x_train_knn, y_train_knn)\n",
        "eval = svc.score(x_test_knn, y_test_knn)\n",
        "print(eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ux_DCgE2mv"
      },
      "source": [
        "flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "x_train_knn, y_train_knn = flatten(encoder(x_train)), y_train\n",
        "x_test_knn, y_test_knn = flatten(encoder(x_test)), y_test\n",
        "\n",
        "\n",
        "# knn algorithm using keras and gpu\n",
        "\n",
        "def knn_algorithm(feature_num, n_neighbors = 7):\n",
        "\n",
        "    x_data_train = tf.compat.v1.placeholder(shape = [None, feature_num], dtype = tf.float32)\n",
        "    y_data_train = tf.compat.v1.placehodler(shape = [None, 7], dtype = tf.float32)\n",
        "    x_data_test = tf.compat.v1.placeholder(shape = [None, feature_num], dtype = tf.float32)\n",
        "\n",
        "    distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train, tf.expand_dims(x_data_test, 1))), axis = 2)\n",
        "    _, top_k_indices = tf.nn.top_k(tf.negative(distance), k = n_neighbors)\n",
        "    sum_up_predictions = tf.reduce_sum(top_k_label, axis = 1)\n",
        "    prediction = tf.argmax(sum_up_predictions, axis = 1)\n",
        "    \n",
        "    return prediction\n",
        "\n",
        "knn_predict = knn_algorithm(21 * 32, n_neighbors = 7)\n",
        "\n",
        "datasets_dict = {\n",
        "    x_data_train : x_train_knn,\n",
        "    x_data_test : x_test_knn,\n",
        "    y_data_train : y_train_knn\n",
        "}\n",
        "\n",
        "# knn training from tensorflow\n",
        "sess = tf.Session()\n",
        "y_test_pred = sess.run(knn_predict, feed_dict = datasets_dict)\n",
        "\n",
        "# evaluation\n",
        "\n",
        "knn_acc = 0\n",
        "\n",
        "for pred, actual in zip(y_test_pred, y_test_knn):\n",
        "    if pred == actual:\n",
        "        knn_acc += 1\n",
        "\n",
        "knn_eval_acc = knn_acc / len(knn_acc)\n",
        "print(\"knn accuracy for testing: \", knn_eval_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5JFZpQglICG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f603e140-3e8d-4ca7-9bf6-d1ddf51b2dfb"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# test file -> convert word embedding vector\n",
        "\n",
        "submission_test = preprocessing(df_test, True)\n",
        "submission_test = tokenizer.texts_to_sequences(submission_test)\n",
        "submission_test = pad_sequences(submission_test, padding = \"post\", dtype = \"int32\", maxlen = maxlen)\n",
        "\n",
        "def softmax_toIdx(predictions):\n",
        "    topic_Idx = np.argmax(predictions, axis = 1).reshape(-1,1)\n",
        "    return topic_Idx\n",
        "\n",
        "# prediction\n",
        "submission_topic = softmax_toIdx(model.predict(submission_test))\n",
        "\n",
        "# submission \n",
        "submission = pd.read_csv(PATH + \"sample_submission.csv\")\n",
        "submission[\"topic_idx\"] = submission_topic\n",
        "submission.to_csv(\"submission.csv\", index = False)\n",
        "files.download(\"submission.csv\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time for preprocessing: 134.63449931144714s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0f3f0e12-3aa6-4912-8364-3687f7228e89\", \"submission.csv\", 73064)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KtyDd1dfveY"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# test file -> convert word embedding vector\n",
        "\n",
        "submission_test = preprocessing(df_test)\n",
        "submission_test = tokenizer.texts_to_sequences(submission_test)\n",
        "submission_test = pad_sequences(submission_test, padding = \"post\", dtype = \"int32\", maxlen = maxlen)\n",
        "\n",
        "def softmax_toIdx(predictions):\n",
        "    topic_Idx = np.argmax(predictions, axis = 1).reshape(-1,1)\n",
        "    return topic_Idx\n",
        "\n",
        "# prediction\n",
        "submission_topic = softmax_toIdx(model_att.predict(submission_test))\n",
        "\n",
        "# submission \n",
        "submission = pd.read_csv(PATH + \"sample_submission.csv\")\n",
        "submission[\"topic_idx\"] = submission_topic\n",
        "submission.to_csv(\"submission_att.csv\", index = False)\n",
        "files.download(\"submission_att.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}